{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T00:19:24.526231Z",
     "start_time": "2020-10-16T00:19:18.941240Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, log_loss\n",
    "from functools import partial, lru_cache\n",
    "from copy import copy\n",
    "from scipy.special import softmax, expit\n",
    "\n",
    "from qiskit import ClassicalRegister, QuantumRegister, QuantumCircuit, Aer, execute, IBMQ\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.tools.visualization import plot_histogram\n",
    "from qiskit.extensions.unitary import unitary\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit.compiler import transpile, assemble\n",
    "S_simulator = Aer.backends(name = 'statevector_simulator')[0]\n",
    "M_simulator = Aer.backends(name = 'qasm_simulator')[0]\n",
    "\n",
    "import functools\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "from operator import itemgetter\n",
    "\n",
    "%matplotlib qt\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Auxiliar functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:35:27.757900Z",
     "start_time": "2020-10-16T02:35:27.685066Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess(vector):\n",
    "    \"\"\"\n",
    "    Input: a vector of size m = 2^N with entries in {-1, 1}.\n",
    "    Output: a (m, 2) numpy array with the form:\n",
    "    [[1 list([])]\n",
    "     [-1 list([])]\n",
    "     [1 list([])]\n",
    "     [1 list([])]]\n",
    "    where the frst column represents the sign and the second is the position in binary.\n",
    "    \"\"\"\n",
    "    # Factorize the sign\n",
    "    i_unsigned = np.multiply(-1, vector)\n",
    "    # To binary string\n",
    "    i_binary = [bin(int(n)) for n in i_unsigned]\n",
    "    # Remove the -0b or 0b par of the binary representation. bin(7) = 0b111 -> 111\n",
    "    for index, e in enumerate(i_binary):\n",
    "        if(e[0] == '-'):\n",
    "            #i_binary[index] = [-1, [int(e) for e in bin(index)[2:]]]\n",
    "            i_binary[index] = [-1, list(map(int, str(int(bin(index)[2:]))))]\n",
    "        else:\n",
    "            #i_binary[index] = [1, [int(e) for e in bin(index)[2:]]]\n",
    "            i_binary[index] = [1, list(map(int, str(int(bin(index)[2:]))))]\n",
    "            \n",
    "    n = int(np.log2(len(i_binary)))\n",
    "    for index, element in enumerate(i_binary):\n",
    "        if (len(element[1]) != n):\n",
    "            while (len(i_binary[index][1]) != n):\n",
    "                i_binary[index][1].insert(0, 0)\n",
    "    #for i in range(len(i_binary)):\n",
    "    #    i_binary[i][1] = i_binary[i][1][::-1]\n",
    "    i_binary = np.array(i_binary)\n",
    "    #print(i_binary)\n",
    "    return i_binary\n",
    "\n",
    "def check_z(binary):\n",
    "    \"\"\"\n",
    "    Input: a preprocessed vector via preprocess().\n",
    "    Output: a vector whose entries represents the qubit to perform a Z-gate.\n",
    "    \"\"\"\n",
    "    positive = True # Controls the sign to achieve\n",
    "    \n",
    "    if (int(binary[0][0]) < 0):\n",
    "        positive = False\n",
    "        \n",
    "    #print(f'The sign will be positive: {positive}')\n",
    "    z_index = []\n",
    "    for index, element in enumerate(binary):\n",
    "        counts = Counter(element[1])\n",
    "        #print(counts[1])\n",
    "        if (counts[1] == 1):\n",
    "            if (positive):\n",
    "                if (int(binary[index][0]) == -1):\n",
    "                    #print(f'Z gate in qubit {np.where(np.array(binary[2**i][1]) == 1)[0]}')\n",
    "                    z_index.append(int(np.where(np.array(binary[index][1]) == 1)[0][0]))\n",
    "            else:\n",
    "                if (int(binary[index][0]) == 1):\n",
    "                    #print(f'Z gate in qubit {np.where(np.array(binary[2**i][1]) == 1)[0]}')\n",
    "                    z_index.append(int(np.where(np.array(binary[index][1]) == 1)[0][0]))\n",
    "    #print(z_index)\n",
    "    #z_index = reindex(int(np.log2(len(i_binary))), z_index)\n",
    "    return z_index\n",
    "\n",
    "def apply_z(binary, Z):\n",
    "    \"\"\"\n",
    "    Input: the preprocessed vector and a vector containing the qubits to apply a Z-gate.\n",
    "    Output: the resultant vector with the signs flipped accordingly to the action of the Z-gates.\n",
    "    \"\"\"\n",
    "    '''for ind, e in enumerate(binary):\n",
    "        counts = Counter(e[1])\n",
    "        if counts[1] > 0:\n",
    "            ones = np.where(np.array(e[1]) == 1)[0]\n",
    "            #print(counts[1], e[1], ones)\n",
    "            for z in Z:\n",
    "                #print(f'z = {z}, ones = {ones}, changes = {z in ones}')\n",
    "                if (z in ones):\n",
    "                    binary[ind][0] *= -1'''\n",
    "    \n",
    "    for z in Z:\n",
    "        mask = np.array(list(map(lambda x : x[z] == 1, binary[:,1])))\n",
    "        binary[mask, 0] *= -1\n",
    "    \n",
    "    #print(binary)\n",
    "    return binary\n",
    "\n",
    "\n",
    "def check_cpz(binary):\n",
    "    \"\"\"\n",
    "    Input: the current preprocessed vector.\n",
    "    Output: the final desired vector and a vector whose elements are vectos containing the qubits to whom apply\n",
    "            the CPZ.\n",
    "    \"\"\"\n",
    "    CPZ = set()\n",
    "    n = int(np.log2(len(binary)))\n",
    "    #print(n)\n",
    "    sequence = 0\n",
    "    '''\n",
    "    # Ordered by the number of ones in its binary representation\n",
    "    aux_binary = sorted(binary, key = lambda item : Counter(item[1])[1])\n",
    "    \n",
    "    # Index holds the positions of the first appearance of n number of ones\n",
    "    index = []\n",
    "    cuenta = 1\n",
    "    for i, e in enumerate(aux_binary):\n",
    "        if (np.sum(e[1]) > cuenta):\n",
    "            index.append(i)\n",
    "            cuenta -= -1\n",
    "    \n",
    "    for ind in index: # Now ind holds where in the aux_binary star to appear elements with 2,3,... ones\n",
    "        for i in range(ind, len(aux_binary)):\n",
    "            if (aux_binary[i][0] != aux_binary[0][0]):\n",
    "                ones = np.where(np.array(aux_binary[i][1]) == 1)[0]\n",
    "                CPZ.add(tuple([sequence, tuple(ones)]))\n",
    "                sequence -= -1\n",
    "                \n",
    "                for j in range(ind, len(aux_binary)):\n",
    "                    pos = np.where(np.array(aux_binary[j][1]) == 1)[0]\n",
    "                    pos_set = set(pos)\n",
    "                    ones_set = set(ones)\n",
    "                    if (set.issubset(ones_set, pos_set)):\n",
    "                        aux_binary[j][0] *= -1\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    for p in range(2, n + 1):\n",
    "        for ind, e in enumerate(binary):\n",
    "            counts = Counter(e[1])\n",
    "            #print(f'manifold of {p}')\n",
    "            if (counts[1] == p) and (binary[0][0] != e[0]):\n",
    "                ones = np.where(np.array(e[1]) == 1)[0]\n",
    "                #cadena = lambda a : str(a)\n",
    "                #unos = cadena(ones)[1:-1]\n",
    "                #CPZ.add(tuple(ones))\n",
    "                CPZ.add(tuple([sequence, tuple(ones)]))\n",
    "                #print(f'applying {tuple([sequence, tuple(ones)])} because {e}')\n",
    "                sequence += 1\n",
    "                \n",
    "                ones_set = set(ones)\n",
    "                mask = np.array(list(map(partial(check_set, ones_set) , binary[:, 1])))\n",
    "                \n",
    "                binary[mask, 0] *= -1\n",
    "                \n",
    "                #for ind, e in enumerate(binary):\n",
    "                #    pos = np.where(np.array(e[1]) == 1)[0]\n",
    "                #    pos_set = set(pos)\n",
    "                #    ones_set = set(ones)\n",
    "                #    if (set.issubset(ones_set, pos_set)):\n",
    "                #        binary[ind][0] *= -1\n",
    "                        #CPZ.append(ones)\n",
    "                        #print(f'C{p}Z = {ones}')\n",
    "    #'''\n",
    "    #print(binary)\n",
    "    CPZ = [list(ele) for _, ele in enumerate(CPZ)]\n",
    "    CPZ = sorted(CPZ, key = lambda l: l[0])\n",
    "    #print(CPZ)\n",
    "    CPZ = [list(e[1]) for e in CPZ]\n",
    "    #sett = [list(e) for e in sett]\n",
    "    #if(binary[0][0] < 0):\n",
    "    #    CPZ = list(map(partial(reindex, int(np.log2(len(binary)))), CPZ))\n",
    "    #CPZ = sorted(CPZ, key = lambda l: (len(l), l.sort()))\n",
    "    return CPZ\n",
    "\n",
    "def check_set(ones_set, pos_set):\n",
    "    return set.issubset(ones_set, set(np.where(np.array(pos_set) == 1)[0]))\n",
    "\n",
    "def vectorize(number, digits):\n",
    "    \"\"\"\n",
    "    Input: an integer in decimal form and the number of final digits as binary.\n",
    "    Output: its representation on binary as an array. Most significant bit as first element of the array.\n",
    "    \"\"\"\n",
    "    digits = 2**(np.ceil(np.log2(digits)))\n",
    "    binary_number = bin(number)[2:]\n",
    "    as_text = str(binary_number)\n",
    "    vectorized_number = [int(d) for d in as_text]\n",
    "    #print(vectorized_number)\n",
    "    if (digits < len(vectorized_number)):\n",
    "        digits = 2**(np.ceil(np.log2(len(vectorized_number))))\n",
    "    if (digits > len(vectorized_number)):\n",
    "        while (len(vectorized_number) != digits):\n",
    "            vectorized_number.insert(0, 0)\n",
    "    #print(vectorized_number)\n",
    "    return np.array(vectorized_number)\n",
    "\n",
    "def o_product(i, w):\n",
    "    return (np.abs(np.dot(i, w))/len(i))**2\n",
    "\n",
    "def sign(p):\n",
    "    #Can be substitute in code by:\n",
    "    #sign = lambda p : [(-1)**i for i in p]\n",
    "    #list(map(sign, inputs))\n",
    "    return [(-1)**i for i in p]\n",
    "\n",
    "def design(p):\n",
    "    return [1 if i < 0 else 0 for i in w]\n",
    "\n",
    "def reindex(N, change):\n",
    "    origin = np.array([i for i in range(N)])\n",
    "    destiny = np.flipud(origin)\n",
    "    \n",
    "    for index, element in enumerate(change):\n",
    "        #print(f'{element} -> {np.where(d == element)[0]}')\n",
    "        change[index] = np.where(destiny == element)[0][0]\n",
    "        \n",
    "    return change\n",
    "\n",
    "def U(qc, q, Z, CPZ):\n",
    "    for z in Z:\n",
    "        #print(f'Z gate in qubit {type(int(z))}')\n",
    "        qc.z(q[int(z)])\n",
    "    for cpz in CPZ:\n",
    "        controls = [q[int(i)] for i in cpz[:-1]]\n",
    "        target = q[int(cpz[-1])]\n",
    "        #print(f'CPZ gate with control {controls} and target {target}')\n",
    "        qc.h(cpz[-1])\n",
    "        #qc.mct(controls, target, None, mode='advanced')\n",
    "        \n",
    "        #try:\n",
    "        #    qc.mct(controls, target, None, mode='advanced')\n",
    "        #except AssertionError:\n",
    "            #print(\"Going to mode noancilla\")\n",
    "        qc.mct(controls, target, None, mode='noancilla')\n",
    "        \n",
    "        qc.h(cpz[-1])\n",
    "    return qc\n",
    "\n",
    "#@lru_cache(maxsize = None)\n",
    "def gates_sequence(vector):\n",
    "    #print('Preprocessing')\n",
    "    binary = preprocess(vector)\n",
    "    #print('Getting Z gates')\n",
    "    Z_GATES = check_z(binary)\n",
    "    #print('Applying Z gates')\n",
    "    binary = apply_z(binary, Z_GATES)\n",
    "    #print('Getting CpZ gates')\n",
    "    CPZ_GATES = check_cpz(binary)\n",
    "    return Z_GATES, CPZ_GATES\n",
    "\n",
    "def perceptron(N = 1, shots = 512, z_gates_w = [], CPZ_gates_w = [], z_gates_i = [], CPZ_gates_i = [], simulation = True):\n",
    "    \n",
    "    q = QuantumRegister(N, name = 'q_r')\n",
    "    #A = QuantumRegister(1, name = 'auxiliar_ancillar')\n",
    "    a = QuantumRegister(1, name = 'a_r')\n",
    "    c = ClassicalRegister(1, name = 'c_r')\n",
    "    qc = QuantumCircuit(q, a, c, name = 'qc')\n",
    "\n",
    "    for index in range(N):\n",
    "        qc.h(q[index])\n",
    "\n",
    "        \n",
    "    qc = U(qc, q, z_gates_i, CPZ_gates_i)\n",
    "    qc = U(qc, q, z_gates_w, CPZ_gates_w)\n",
    "\n",
    "    for index in range(N):\n",
    "        qc.h(q[index])\n",
    "    \n",
    "    for index in range(N):\n",
    "        qc.x(q[index])\n",
    "\n",
    "    #qc.mct(q[:], a[0], None, mode='advanced')\n",
    "    \n",
    "    #try:\n",
    "    #    qc.mct(q[:], a[0], None, mode='advanced')\n",
    "    #except AssertionError:\n",
    "        #print(\"Going to mode noancilla\")\n",
    "    qc.mct(q[:], a[0], None, mode='noancilla')    \n",
    "        \n",
    "    qc.measure(a[0], c)\n",
    "    #print(qc)\n",
    "        \n",
    "    #results = execute(qc, backend = M_simulator, shots = shots).result()\n",
    "    \n",
    "    # Optimized\n",
    "    transpiled_circuit = transpile(qc, M_simulator, optimization_level = 1) # optimization_level = [0, 1, 2, 3]\n",
    "    job = M_simulator.run(assemble(transpiled_circuit, shots = shots))\n",
    "    results = job.result()\n",
    "    \n",
    "    #results = execute(qc, backend = qcomp, shots = shots, memory=True) # For Real Quantum Computing\n",
    "\n",
    "    #job_monitor(results) # For Real Quantum Computing\n",
    "        \n",
    "    #results = results.result() # For Real Quantum Computing\n",
    "    \n",
    "    # Optimized for Real Quantum Computer\n",
    "    #transpiled_circuit = transpile(qc, qcomp, optimization_level = 2) # optimization_level = 0,1,2,3\n",
    "    #job = M_simulator.run(assemble(transpiled_circuit, shots = shots))\n",
    "    #results = job.result()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def fit(qubits = 1, X_train = np.array([[1]]), Y_train = np.array([[1]]), negative_class = 0, positive_class = 1, epochs = 1, shots = 64, threshold = 0.5, Ip = 0.5, In = 0.5, bias = 0, weight_passed = []):\n",
    "    # Train and return a weight vector\n",
    "    n = len(X_train)\n",
    "    result_matrix = np.zeros((epochs, len(X_train)))\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    w = weight_passed\n",
    "    #w = np.random.randint(2, size = 2**qubits) # Random generation of initial weight vector. Sign it at once.\n",
    "    \n",
    "    #w = np.array(X_train[23])\n",
    "    \n",
    "    #print(f'Starting training with qubits = {qubits}, train = {X_train}, target = {Y_train}, epochs = {epochs}, shots = {shots}, Ip = {Ip}, In = {In}')\n",
    "    #print(f'Initial weight vector = {w}')\n",
    "    \n",
    "    weights = []\n",
    "    \n",
    "    true_labels = np.array([x == number_negative_class for x in Y_train], dtype = 'int')\n",
    "\n",
    "    for epoch in notebook.tqdm(range(epochs), desc = f'Epoches'):\n",
    "        errors = 0\n",
    "        correct = 0\n",
    "        pred_labels = []\n",
    "        for index, training_element in enumerate(notebook.tqdm(X_train, desc = f'Training {epoch}')):\n",
    "\n",
    "            pattern = sign(training_element) # Signing the training pattern.\n",
    "            \n",
    "            wei = sign(w) # Signing the weight vector\n",
    "            #print('Calculating Z gates')\n",
    "            #print(pattern)\n",
    "            z_gates_i, CPZ_gates_i = gates_sequence(tuple(pattern)) # Gates to apply to the training pattern vector\n",
    "            #print('Calculating CpZ gates')\n",
    "            z_gates_w, CPZ_gates_w = gates_sequence(tuple(wei)) # Gates to apply to the weight vector\n",
    "            \n",
    "            #print('Ahora sí, Quantum Realm')\n",
    "            \n",
    "            ############################  Quantum Proccess  ############################\n",
    "            \n",
    "            results = perceptron(qubits, shots, z_gates_w, CPZ_gates_w, z_gates_i, CPZ_gates_i)\n",
    "            \n",
    "            #########################  End of Quantum Proccess  #########################\n",
    "            \n",
    "            counts = results.get_counts()\n",
    "        \n",
    "            #list_count_value = [ (v,oq.From_binary(k)) for k, v in counts.items()]\n",
    "\n",
    "            #sorte = sorted(list_count_value, key = itemgetter(0))\n",
    "        \n",
    "            #readout = sorte[0][1] * sorte[0][0] / shots\n",
    "            \n",
    "            readout = counts.get('1', shots) / shots\n",
    "            \n",
    "            #try:\n",
    "            #    readout = counts['1'] / shots\n",
    "            #except KeyError:\n",
    "            #    readout = 0\n",
    "            \n",
    "            #print(readout)\n",
    "            \n",
    "            clazz = negative_class if (readout + bias) < threshold else positive_class # Classification part.\n",
    "            \n",
    "            pred_labels.append(clazz)\n",
    "            \n",
    "            result_matrix[epoch][index] = readout + bias\n",
    "            #print(f'Weight vector = {w} and Training element = {training_element}')\n",
    "            if (Y_train[index] == clazz):\n",
    "                # Correctly classified. We do not modify the weight vector and we continue.\n",
    "                correct -= -np.power(np.inf, np.log(1))\n",
    "                #if clazz:\n",
    "                    #Ip *= (n - correct) / float(n)\n",
    "                    #Ip *= 1.0 / np.log(3 + correct)\n",
    "                    #Ip *= np.exp(-0.001 * correct)\n",
    "                    #Ip *= 1.0 / (1.0 + 0.01 * correct)\n",
    "                    #Ip *= .982**np.floor((correct + 1) / 10)\n",
    "                #else:\n",
    "                    #In *= (n - correct) / float(n)\n",
    "                    #In *= 1.0 / np.log(3 + correct)\n",
    "                    #In *= np.exp(-0.001 * correct)\n",
    "                    #In *= 1.0 / (1.0 + 0.01 * correct)\n",
    "                    #In *= .982**np.floor((correct + 1) / 10)\n",
    "                continue # Skip the execution to the next iteration\n",
    "            # If we reach this point the classification was incorrect\n",
    "            #if (clazz < Y_train[index]): # Classified as 0 (negative) when is 1 (positive)\n",
    "            if (clazz == negative_class): # Classified as (negative) when is (positive)\n",
    "                # We flip +-1 signs Ip fraction where i and w coincide\n",
    "                coincide = np.argwhere(training_element == w).flatten()\n",
    "                pos = np.array(list(set(np.random.choice(coincide, int(np.floor(len(coincide) * Ip)), replace = False)))) if len(coincide) > 0 else np.array([])\n",
    "                #print(f'Missclasiffied as 0. Before changes: {Counter(w)} with len(coincide) * Ip = {int(np.ceil(len(coincide) * Ip))}')\n",
    "                #for indexed in pos:\n",
    "                    #print('entre en Ip')\n",
    "                #    w[indexed] = (w[indexed] + 1) % 2\n",
    "#                print(f'Coincide in {len(coincide)} and change {len(pos)} bits')\n",
    "                try:\n",
    "                    w[pos] = (w[pos] + 1) % 2\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                #print(f'Missclasiffied as 0. After  changes: {Counter(w)} with len(coincide) * Ip = {int(np.ceil(len(coincide) * Ip))}')\n",
    "            else: # Classified as 1 (positive) when is 0 (negative)\n",
    "                # We flip +-1 signs In fraction where i and w coincide\n",
    "                coincide = np.argwhere(training_element == w).flatten()\n",
    "                pos = np.array(list(set(np.random.choice(coincide, int(np.floor(len(coincide) * In)), replace = False)))) if len(coincide) > 0 else np.array([])\n",
    "                #print(f'Missclasified as 1. Before changes: {Counter(w)} with len(coincide) * In = {int(np.ceil(len(coincide) * In))}')\n",
    "                #for indexed in pos:\n",
    "                    #print('entre en In')\n",
    "                #    w[indexed] = (w[indexed] + 1) % 2\n",
    "#                print(f'Coincide in {len(coincide)} and change {len(pos)} bits')\n",
    "                try:\n",
    "                    w[pos] = (w[pos] + 1) % 2\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                #print(f'Missclasified as 1. After  changes: {Counter(w)} with len(coincide) * In = {int(np.ceil(len(coincide) * In))}')\n",
    "            errors -= -1\n",
    "        print(f'Errors = {errors} for accuracy of = {1 - errors/len(X_train)}')\n",
    "        #print(f'Final weight vector = {w}')\n",
    "        weights.append(w)\n",
    "        pred_labels = np.array([x == number_negative_class for x in pred_labels], dtype = 'int')\n",
    "        loss = 0 if number_negative_class == number_positive_class else log_loss(true_labels, pred_labels) \n",
    "    return w, result_matrix, weights, (1 - errors/len(X_train) , loss)\n",
    "\n",
    "def predict(qubits = 1, X_test = np.array([[1]]), negative_class = 0, positive_class = 1, shots = 64, threshold = 0.5, w = 0, bias = 0):\n",
    "    # Train and return a weight vector\n",
    "    result_matrix = np.zeros(len(X_test))\n",
    "    readout_matrix = np.zeros(len(X_test))\n",
    "    np.random.seed(10)\n",
    "    Y_predicted = np.zeros(len(X_test))\n",
    "    wei = sign(w) # Signing the weight vector\n",
    "    z_gates_w, CPZ_gates_w = gates_sequence(tuple(wei)) # Gates to apply to the weight vector\n",
    "    \n",
    "    #print(f'Starting predict with qubits = {qubits}, train = {X_test}, shots = {shots}')\n",
    "    #print(f'Passed weight vector = {w}')\n",
    "         \n",
    "    for index, training_element in enumerate(notebook.tqdm(X_test, desc = 'Predicting')):\n",
    "            \n",
    "        pattern = sign(training_element) # Signing the training pattern.\n",
    "            \n",
    "        z_gates_i, CPZ_gates_i = gates_sequence(tuple(pattern)) # Gates to apply to the training pattern vector\n",
    "            \n",
    "        ############################  Quantum Proccess  ############################\n",
    "            \n",
    "        results = perceptron(qubits, shots, z_gates_w, CPZ_gates_w, z_gates_i, CPZ_gates_i)\n",
    "            \n",
    "        #########################  End of Quantum Proccess  #########################\n",
    "            \n",
    "        counts = results.get_counts()\n",
    "        \n",
    "        #list_count_value = [ (v,oq.From_binary(k)) for k, v in counts.items()]\n",
    "\n",
    "        #sorte = sorted(list_count_value, key = itemgetter(0))\n",
    "        \n",
    "        #readout = sorte[0][1] * sorte[0][0] / shots\n",
    "        \n",
    "        readout = counts.get('1', shots) / shots\n",
    "        \n",
    "        #try:\n",
    "        #    readout = counts['1'] / shots\n",
    "        #except KeyError:\n",
    "        #    readout = 0\n",
    "        \n",
    "        #print(readout)\n",
    "            \n",
    "        clazz = negative_class if (readout + bias) < threshold else positive_class # Classification part.\n",
    "            \n",
    "        result_matrix[index] = clazz\n",
    "        \n",
    "        readout_matrix[index] = readout + bias\n",
    "\n",
    "    return result_matrix, readout_matrix\n",
    "\n",
    "def evaluate(Y_test, predicted, negative_class, positive_class):\n",
    "    correct = np.argwhere(Y_test == predicted)\n",
    "    accuracy = len(correct) / len(predicted)\n",
    "    ones_and_zeros = [Y_test[ind][0] for ind in correct]\n",
    "    counts = Counter(ones_and_zeros)\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    \n",
    "    Y_test_aux = np.zeros_like(Y_test)\n",
    "    predicted_aux = np.zeros_like(predicted)\n",
    "    \n",
    "    #Y_test_aux[Y_test == negative_class] = 0\n",
    "    #predicted_aux[predicted == negative_class] = 0\n",
    "    Y_test_aux[Y_test == positive_class] = 1\n",
    "    predicted_aux[predicted == positive_class] = 1\n",
    "    \n",
    "    for i in range(len(predicted_aux)):\n",
    "        confusion_matrix[int(Y_test_aux[i])][int(predicted_aux[i])] += 1\n",
    "    return accuracy, counts, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names = None, cmap = None, normalize = True, labels = True, title = 'Confusion Matrix'):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "        \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        \n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "        \n",
    "    if labels:\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]), horizontalalignment = 'center', color = 'white' if cm[i, j] > thresh else 'black', fontsize = 20)\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]), horizontalalignment = 'center', color = 'white' if cm[i, j] > thresh else 'black', fontsize = 20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy = {:0.4f}; misclass = {:0.4f}'.format(accuracy, misclass))\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "def save_weight(filename = 'weights.txt', mode = 'a+', weight = []):\n",
    "    with open(filename, mode) as file:\n",
    "        file.write(f'{number_negative_class, number_positive_class}:')\n",
    "        for p in w:\n",
    "            file.write(f'{p},')\n",
    "        file.write('\\n')\n",
    "        \n",
    "def retrieve_weights_from_file(filename = 'weights.txt', full = False):\n",
    "    with open(filename, 'r+') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        cuadratic = lambda w : int(np.abs((1 - np.sqrt(1 + 8 * w)) / 2))\n",
    "        \n",
    "        nc = int(np.sqrt(len(lines))) if full else cuadratic(len(lines))\n",
    "        \n",
    "        weights_matrix = np.empty((nc, nc), dtype = object)\n",
    "    \n",
    "        #print(weights_matrix)\n",
    "    \n",
    "        for line in lines:\n",
    "            #print(line, end = '\\n')\n",
    "            xy, peso = line.split(sep = ':')[0], line.split(sep = ':')[1]\n",
    "            weight = np.array(list(map(int , peso.split(sep = ',')[:-1])))\n",
    "            coordinates = [int(c) for c in xy if c.isdigit()]\n",
    "            #print(f'Coordenates: {coordinates[0], coordinates[1]}, weight: {weight}')\n",
    "            weights_matrix[coordinates[0]][coordinates[1]] = weight\n",
    "            if not full:\n",
    "                weights_matrix[coordinates[1]][coordinates[0]] = weight\n",
    "    \n",
    "        #print(weights_matrix)\n",
    "    return weights_matrix\n",
    "\n",
    "def retrieve_weights_from_file_total(filename = 'weights.txt'):\n",
    "    with open(filename, 'r+') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        weights_vector = []\n",
    "        \n",
    "        for line in lines:\n",
    "            xy, peso = line.split(sep = ':')[0], line.split(sep = ':')[1]\n",
    "            weight = np.array(list(map(int , peso.split(sep = ',')[:-1])))\n",
    "            weights_vector.append(weight)\n",
    "            \n",
    "        \n",
    "    return np.array(weights_vector)\n",
    "\n",
    "def print_weights_matrix(weights_matrix):\n",
    "    n_classes = weights_matrix.shape[0]\n",
    "    fig, axs = plt.subplots(2, n_classes // 2, figsize=(20, 10))\n",
    "    count = 0\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(n_classes // 2):\n",
    "            ax = axs[i][j]\n",
    "        \n",
    "            #c = ax.pcolor(thetas[i + j][1:].reshape(28, 28), cmap = 'gray')\n",
    "            try:\n",
    "                c = ax.imshow(weights_matrix[i * 5 + j].reshape(8, 8), cmap = 'gray_r', interpolation='nearest')\n",
    "                ax.axis('off')\n",
    "                ax.axis('equal')\n",
    "                ax.set_title(f'Weight vector for {i * 5 + j}').set_position([0.5, 0.9])\n",
    "                count += 1\n",
    "            except IndexError:\n",
    "                continue\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.colorbar(c)\n",
    "    plt.show()\n",
    "    \n",
    "def multi_class_prediction_OVA(qubits = 1, classification_patterns = np.array([[1]]), shots = 64, test_threshold = 0.35, weights_matrix = np.zeros((1,1)), bias = 0):\n",
    "\n",
    "    # Declaring and populating the Classification Matrix\n",
    "\n",
    "    patterns = len(classification_patterns)\n",
    "    holder_for_classes = np.zeros((patterns, 10), dtype = 'int64')\n",
    "    holder_for_readouts = np.zeros((patterns, 10), dtype = 'float64')\n",
    "    \n",
    "    '''for i, x in enumerate(classification_patterns):\n",
    "        for j, w in enumerate(weights_matrix):\n",
    "            asigned_class, read_out = predict(qubits = Q, X_test = [x], negative_class = j, positive_class = 10, shots = shots, threshold = test_threshold, w = weights_matrix[j], bias = bias)\n",
    "            holder_for_classes[i, j] = asigned_class\n",
    "            holder_for_readouts[i, j] = read_out'''\n",
    "            \n",
    "    for i, w in enumerate(weights_matrix):\n",
    "        asigned_class, read_out = predict(qubits = Q, X_test = classification_patterns, negative_class = i, positive_class = 10, shots = shots, threshold = test_threshold, w = weights_matrix[i], bias = bias)\n",
    "        holder_for_classes[: ,i] = asigned_class\n",
    "        holder_for_readouts[:, i] = read_out\n",
    "    \n",
    "    return holder_for_classes, holder_for_readouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training binary imbalanced classifiers $Full Digits$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:11.096613Z",
     "start_time": "2020-10-16T02:03:10.908938Z"
    }
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "data = np.loadtxt(\"C:/Users/jeff_/OneDrive - Instituto Politecnico Nacional/Datasets/Digits/optdigits.tra\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:11.249699Z",
     "start_time": "2020-10-16T02:03:11.244713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting images and labels from digits\n",
    "images = digits.images\n",
    "targets = digits.target\n",
    "images_tr = data[:,:-1]\n",
    "labels_tr = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:11.703722Z",
     "start_time": "2020-10-16T02:03:11.699767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count for digits: Counter({3: 183, 1: 182, 5: 182, 4: 181, 6: 181, 9: 180, 7: 179, 0: 178, 2: 177, 8: 174})\n"
     ]
    }
   ],
   "source": [
    "targets_count = Counter(targets)\n",
    "print(f'Total count for digits: {targets_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:12.337148Z",
     "start_time": "2020-10-16T02:03:12.332145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"images_and_labels = list(zip(images, targets))\\nfor index, (image, label) in enumerate(images_and_labels[45:65]):\\n    plt.subplot(2, 10, index + 1)\\n    plt.axis('off')\\n    plt.imshow(np.round(image / np.max(image)).reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\\n    plt.title('L: %i' % label)\""
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''images_and_labels = list(zip(images, targets))\n",
    "for index, (image, label) in enumerate(images_and_labels[45:65]):\n",
    "    plt.subplot(2, 10, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.round(image / np.max(image)).reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('L: %i' % label)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:14.783739Z",
     "start_time": "2020-10-16T02:03:14.780759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting 0 and 1 from digits\n",
    "number_negative_class = 9\n",
    "number_positive_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:15.152578Z",
     "start_time": "2020-10-16T02:03:15.148622Z"
    }
   },
   "outputs": [],
   "source": [
    "targets[targets != number_negative_class] = number_positive_class\n",
    "labels_tr[labels_tr != number_negative_class] = number_positive_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:15.433550Z",
     "start_time": "2020-10-16T02:03:15.428593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count for digits: Counter({10: 1617, 9: 180})\n",
      "Total count for digits: Counter({10.0: 3441, 9.0: 382})\n"
     ]
    }
   ],
   "source": [
    "targets_count = Counter(targets)\n",
    "print(f'Total count for digits: {targets_count}')\n",
    "print(f'Total count for digits: {Counter(labels_tr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:15.689046Z",
     "start_time": "2020-10-16T02:03:15.684059Z"
    }
   },
   "outputs": [],
   "source": [
    "# NO SPLITTING FOR RESUSTITUTION ERROR MEASURE\n",
    "X_train = copy(images_tr)\n",
    "X_test = copy(images)\n",
    "Y_train = copy(labels_tr)\n",
    "Y_test = copy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:15.986604Z",
     "start_time": "2020-10-16T02:03:15.982579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"images_and_labels = list(zip(X_test, Y_test))\\nfor index, (image, label) in enumerate(images_and_labels[10:30]):\\n    plt.subplot(2, 10, index + 1)\\n    plt.axis('off')\\n    plt.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\\n    plt.title('T: %i' % label)\""
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''images_and_labels = list(zip(X_test, Y_test))\n",
    "for index, (image, label) in enumerate(images_and_labels[10:30]):\n",
    "    plt.subplot(2, 10, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('T: %i' % label)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:16.249400Z",
     "start_time": "2020-10-16T02:03:16.245399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping digits\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:16.515233Z",
     "start_time": "2020-10-16T02:03:16.511249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3823, 64)\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:17.000893Z",
     "start_time": "2020-10-16T02:03:16.781290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing digits by mapping in interval\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = np.array(list(map(lambda x : 0 if 0 <= x < 10 else 1, X_test[i])))\n",
    "    \n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = np.array(list(map(lambda x : 0 if 0 <= x < 10 else 1, X_train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:17.113018Z",
     "start_time": "2020-10-16T02:03:17.108031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = X_train.tolist()\\nX_test = X_test.tolist()'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:17.361172Z",
     "start_time": "2020-10-16T02:03:17.357149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c = plt.imshow(np.array(X_train[35]).reshape(8, 8))\\nplt.colorbar(c)'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''c = plt.imshow(np.array(X_train[35]).reshape(8, 8))\n",
    "plt.colorbar(c)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fitting the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:03:18.794137Z",
     "start_time": "2020-10-16T02:03:18.788187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "groups = {'acccuracy': ['acc', 'val_acc'], 'log-loss': ['loss', 'val_loss']}\n",
    "plotlosses = PlotLosses(groups=groups)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:08:04.826241Z",
     "start_time": "2020-10-16T02:03:19.021734Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1c20030d7d402d88fa1c7bf6155120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoches', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fea6258f6d41beb6aa360d0e024a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training 0', max=3823.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Errors = 2721 for accuracy of = 0.28825529688726126\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f93509eb744c9d83e5a9a5b5aec0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 0.19254312743461324, precision: 0.10698824984539271, recall: 0.9611111111111111, f1: 0.19254312743461324\n"
     ]
    }
   ],
   "source": [
    "Q = 6\n",
    "test_threshold = 0.35\n",
    "rs = 0\n",
    "w = X_train[Y_train == number_negative_class][0].astype(int)\n",
    "#w = np.random.randint(2, size = 2 ** Q)\n",
    "shots = 1024 * 8 #8_192\n",
    "while rs < 0.8:\n",
    "    w, m, weights, ae = fit(qubits = Q, X_train = X_train[:], Y_train = Y_train[:], negative_class = number_negative_class, positive_class = number_positive_class, epochs = 1, shots = shots, threshold = 0.35, Ip = .8, In = .1, bias = 0.0, weight_passed = w)\n",
    "    classification, readouts = predict(qubits = Q, X_test = X_test, negative_class = number_negative_class, positive_class = number_positive_class, shots = shots, threshold = test_threshold, w = weights[0], bias = 0.0)\n",
    "    acc = accuracy_score(Y_test, classification)\n",
    "    ps = precision_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)\n",
    "    rs = recall_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)\n",
    "    f1s = f1_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)\n",
    "    print(f'acc: {acc}, precision: {ps}, recall: {rs}, f1: {f1s}')\n",
    "    loss = 0 if number_negative_class == number_positive_class else log_loss(Y_test, np.array([x == number_negative_class for x in classification], dtype = 'int'))\n",
    "    plotlosses.update({\n",
    "        'acc': ae[0],\n",
    "        'val_acc': acc,\n",
    "        'loss': ae[1],\n",
    "        'val_loss': loss\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:08:05.236178Z",
     "start_time": "2020-10-16T02:08:04.827238Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acccuracy\n",
      "\ttraining         \t (min:    0.288, max:    0.288, cur:    0.288)\n",
      "\tvalidation       \t (min:    0.193, max:    0.193, cur:    0.193)\n",
      "log-loss\n",
      "\ttraining         \t (min:   24.583, max:   24.583, cur:   24.583)\n",
      "\tvalidation       \t (min:    6.650, max:    6.650, cur:    6.650)\n"
     ]
    }
   ],
   "source": [
    "plotlosses.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:08:07.742998Z",
     "start_time": "2020-10-16T02:08:05.237142Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from winsound import Beep\n",
    "Beep(100, 500)\n",
    "Beep(100, 500)\n",
    "Beep(100, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:08:07.748676Z",
     "start_time": "2020-10-16T02:08:07.744641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:08:07.760598Z",
     "start_time": "2020-10-16T02:08:07.751623Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q = 6\\nw, m, weights = fit(qubits = Q, X_train = X_train[:], Y_train = Y_train[:], negative_class = number_negative_class, positive_class = number_positive_class, epochs = 1, shots = 1024, threshold = 0.35, Ip = .8, In = .1, bias = 0.0)'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q = 6\n",
    "w, m, weights = fit(qubits = Q, X_train = X_train[:], Y_train = Y_train[:], negative_class = number_negative_class, positive_class = number_positive_class, epochs = 1, shots = 1024, threshold = 0.35, Ip = .8, In = .1, bias = 0.0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:36:05.126069Z",
     "start_time": "2020-10-16T02:36:05.059249Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = plt.imshow(np.array(w).reshape(8, 8), cmap = 'gray_r')\n",
    "plt.colorbar(c)\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predicting and evaluating the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.559870Z",
     "start_time": "2020-10-16T02:08:07.852352Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89acf9c42bbc4513b352216dc7ea182f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_threshold = 0.35\n",
    "classification, readouts = predict(qubits = Q, X_test = X_test, negative_class = number_negative_class, positive_class = number_positive_class, shots = shots, threshold = test_threshold, w = weights[0], bias = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.569831Z",
     "start_time": "2020-10-16T02:09:26.561865Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.1930996104618809\n",
      "Counts = Counter({9: 174, 10: 173})\n",
      "Confusion Matrix = \n",
      "[[ 174.    6.]\n",
      " [1444.  173.]]\n"
     ]
    }
   ],
   "source": [
    "accuracy, counts, confusion_matriX = evaluate(Y_test, classification, number_negative_class, number_positive_class)\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print(f'Counts = {counts}')\n",
    "print(f'Confusion Matrix = \\n{confusion_matriX}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:36:16.556364Z",
     "start_time": "2020-10-16T02:36:16.459656Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matriX, target_names = np.array([number_negative_class, number_positive_class]), labels = True, normalize = False)\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.671558Z",
     "start_time": "2020-10-16T02:09:26.667551Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 174.,    6.],\n",
       "       [1444.,  173.]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matriX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.679519Z",
     "start_time": "2020-10-16T02:09:26.673536Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1930996104618809"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.688524Z",
     "start_time": "2020-10-16T02:09:26.680516Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 174,    6],\n",
       "       [1444,  173]], dtype=int64)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.695516Z",
     "start_time": "2020-10-16T02:09:26.689493Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10754017305315204"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.702511Z",
     "start_time": "2020-10-16T02:09:26.696474Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.709439Z",
     "start_time": "2020-10-16T02:09:26.703500Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19354838709677416"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, classification, average = 'binary', pos_label = number_negative_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.716472Z",
     "start_time": "2020-10-16T02:09:26.710439Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5370103099902632"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Precision Score\n",
    "precision_score(Y_test, classification, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.723454Z",
     "start_time": "2020-10-16T02:09:26.717450Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5368274582560297"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Recall Score\n",
    "recall_score(Y_test, classification, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.730416Z",
     "start_time": "2020-10-16T02:09:26.724433Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.193099360586249"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average F1 Score\n",
    "f1_score(Y_test, classification, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.738361Z",
     "start_time": "2020-10-16T02:09:26.731381Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The accuracy is 0.1930996104618809.'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"b6a88f93-45d7-491f-8c8d-693331dda078\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"b6a88f93-45d7-491f-8c8d-693331dda078\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"The accuracy is 0.1930996104618809.\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -o\n",
    "f'The accuracy is {accuracy}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:36:27.759198Z",
     "start_time": "2020-10-16T02:36:27.667442Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5368274582560296\n"
     ]
    }
   ],
   "source": [
    "test = [0 if ele == number_negative_class else 1 for ele in Y_test]\n",
    "classi = [0 if ele == number_negative_class else 1 for ele in classification]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test, classi)\n",
    "\n",
    "def ROC_curve(fpr,tpr):\n",
    "    # Seaborn's beautiful styling\n",
    "    sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "    print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)], fontsize = 15)\n",
    "    plt.xticks([i/20.0 for i in range(21)], fontsize = 15)\n",
    "    plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "    plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve', fontsize = 20)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "ROC_curve(fpr,tpr)\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "sns.set_style('white', {'axes.facecolor': '0.9'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.830220Z",
     "start_time": "2020-10-16T02:09:26.825233Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3980712890625"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readouts[Y_test == number_negative_class].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.836204Z",
     "start_time": "2020-10-16T02:09:26.831217Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1444,)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readouts[(readouts < test_threshold) & (Y_test == number_positive_class)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:09:26.843186Z",
     "start_time": "2020-10-16T02:09:26.838198Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readouts[(readouts > test_threshold) & (Y_test == number_negative_class)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Manual process analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:03.661915Z",
     "start_time": "2020-10-16T02:34:03.654924Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:04.070290Z",
     "start_time": "2020-10-16T02:34:04.066301Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ..., 10,  9, 10])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:04.351945Z",
     "start_time": "2020-10-16T02:34:04.346960Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1791 1794 1796]\n"
     ]
    }
   ],
   "source": [
    "fails = np.where(classification != Y_test)[0]\n",
    "print(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:04.911475Z",
     "start_time": "2020-10-16T02:34:04.802801Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2197265625\n",
      "0.19140625\n",
      "0.3525390625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.31640625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.25\n",
      "0.09765625\n",
      "0.140625\n",
      "0.25\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.0791015625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.0625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.25\n",
      "0.09765625\n",
      "0.2822265625\n",
      "0.0478515625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.140625\n",
      "0.25\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.3525390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.3525390625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.31640625\n",
      "0.25\n",
      "0.3525390625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.25\n",
      "0.140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.3525390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.0791015625\n",
      "0.25\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.3525390625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.3525390625\n",
      "0.0791015625\n",
      "0.25\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.25\n",
      "0.25\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.25\n",
      "0.25\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.25\n",
      "0.140625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.0625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.3525390625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.25\n",
      "0.0625\n",
      "0.25\n",
      "0.25\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.0625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.25\n",
      "0.3525390625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.390625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.25\n",
      "0.25\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.390625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.25\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.3525390625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.3525390625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.25\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.0625\n",
      "0.09765625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.3525390625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.25\n",
      "0.09765625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.0244140625\n",
      "0.25\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.25\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.25\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.0625\n",
      "0.140625\n",
      "0.25\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.25\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.0625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.0625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.3525390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.3525390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.0625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.3525390625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.0478515625\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.25\n",
      "0.25\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.25\n",
      "0.0478515625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.25\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.25\n",
      "0.09765625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.3525390625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.0791015625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.0625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.140625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.0625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.0625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.0244140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.09765625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.25\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.09765625\n",
      "0.09765625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.3525390625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.0625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.0625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.140625\n",
      "0.0625\n",
      "0.140625\n",
      "0.140625\n",
      "0.25\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.31640625\n",
      "0.25\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.0791015625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.25\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.140625\n",
      "0.25\n",
      "0.0625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.140625\n",
      "0.25\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.2822265625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.25\n",
      "0.25\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.3525390625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.140625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.25\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.0244140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.0478515625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.0244140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.0478515625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.31640625\n",
      "0.1181640625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.1181640625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.2822265625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.25\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.0791015625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.0625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.09765625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.140625\n",
      "0.25\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.0478515625\n",
      "0.19140625\n",
      "0.25\n",
      "0.25\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.31640625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.25\n",
      "0.3525390625\n",
      "0.31640625\n",
      "0.2197265625\n",
      "0.09765625\n",
      "0.0791015625\n",
      "0.2197265625\n",
      "0.2822265625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.31640625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.19140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.25\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.2822265625\n",
      "0.31640625\n",
      "0.3525390625\n",
      "0.31640625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.09765625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.0791015625\n",
      "0.1650390625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.140625\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.19140625\n",
      "0.0791015625\n",
      "0.0625\n",
      "0.1650390625\n",
      "0.1181640625\n",
      "0.2822265625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.19140625\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.140625\n",
      "0.140625\n",
      "0.19140625\n",
      "0.25\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.1181640625\n",
      "0.1650390625\n",
      "0.19140625\n",
      "0.1181640625\n",
      "0.25\n",
      "0.19140625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.25\n",
      "0.31640625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.140625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.25\n",
      "0.1181640625\n",
      "0.25\n",
      "0.140625\n",
      "0.19140625\n",
      "0.09765625\n",
      "0.1650390625\n",
      "0.2822265625\n",
      "0.25\n",
      "0.03515625\n",
      "0.1650390625\n",
      "0.2197265625\n",
      "0.140625\n",
      "0.1181640625\n",
      "0.09765625\n",
      "0.0791015625\n",
      "0.140625\n",
      "0.2197265625\n",
      "0.0791015625\n",
      "0.19140625\n",
      "0.2197265625\n",
      "0.2197265625\n",
      "0.1650390625\n",
      "0.1650390625\n",
      "0.19140625\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "for x in X_test[fails]:\n",
    "    print(np.power((np.where(weights[0] == x)[0].shape[0] - np.where(weights[0] != x)[0].shape[0]) / x.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:05.763549Z",
     "start_time": "2020-10-16T02:34:05.755583Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02404785 0.03625488 0.07543945 0.08203125 0.08239746 0.09448242\n",
      " 0.09509277 0.10021973 0.10290527 0.11450195 0.11547852 0.11621094\n",
      " 0.11804199 0.1184082  0.11865234 0.12255859 0.12304688 0.13562012\n",
      " 0.13708496 0.13818359 0.13842773 0.1385498  0.13891602 0.13916016\n",
      " 0.13964844 0.13977051 0.14001465 0.14013672 0.14099121 0.14099121\n",
      " 0.14160156 0.14208984 0.14233398 0.14245605 0.14282227 0.14294434\n",
      " 0.14318848 0.14477539 0.14672852 0.14892578 0.16052246 0.1607666\n",
      " 0.16235352 0.16296387 0.16308594 0.16320801 0.16345215 0.16394043\n",
      " 0.16467285 0.16491699 0.1652832  0.16625977 0.16699219 0.16699219\n",
      " 0.16711426 0.16711426 0.16796875 0.16845703 0.17077637 0.17614746\n",
      " 0.18457031 0.18554688 0.18579102 0.18579102 0.18591309 0.18737793\n",
      " 0.18737793 0.18847656 0.18847656 0.18884277 0.18908691 0.18920898\n",
      " 0.18945312 0.18969727 0.19042969 0.19128418 0.19165039 0.1920166\n",
      " 0.19213867 0.19226074 0.19238281 0.19299316 0.1932373  0.19470215\n",
      " 0.1953125  0.19543457 0.1986084  0.19958496 0.21118164 0.21264648\n",
      " 0.21313477 0.21350098 0.21374512 0.21411133 0.21520996 0.21557617\n",
      " 0.21630859 0.2166748  0.21716309 0.21740723 0.21789551 0.21789551\n",
      " 0.21789551 0.21850586 0.21911621 0.21948242 0.2199707  0.22021484\n",
      " 0.22058105 0.22106934 0.22106934 0.22167969 0.22180176 0.2220459\n",
      " 0.2220459  0.22229004 0.2232666  0.22351074 0.22424316 0.22595215\n",
      " 0.22888184 0.24035645 0.24279785 0.24438477 0.24523926 0.24560547\n",
      " 0.24609375 0.24645996 0.24768066 0.24768066 0.24804688 0.24853516\n",
      " 0.24951172 0.24975586 0.24975586 0.25048828 0.25048828 0.25158691\n",
      " 0.25256348 0.25390625 0.25439453 0.25500488 0.25634766 0.2565918\n",
      " 0.25683594 0.25744629 0.25744629 0.25769043 0.25793457 0.2598877\n",
      " 0.26794434 0.27075195 0.27233887 0.27502441 0.27856445 0.27978516\n",
      " 0.28088379 0.28234863 0.2824707  0.28356934 0.28405762 0.28869629\n",
      " 0.28930664 0.3137207  0.31494141 0.31518555 0.31604004 0.31677246\n",
      " 0.31726074 0.31787109 0.31982422 0.34338379 0.34765625 0.34924316\n",
      " 0.35144043 0.35595703 0.35681152 0.35693359 0.390625   0.39807129]\n",
      "\n",
      "[0.02331543 0.02490234 0.0255127  ... 0.56872559 0.59912109 0.61083984]\n",
      "[0.02331543 0.02490234 0.0255127  ... 0.35693359 0.390625   0.39807129]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(readouts[np.where(Y_test == number_negative_class)]), end = '\\n\\n')\n",
    "print(np.sort(readouts[np.where(Y_test == number_positive_class)]))\n",
    "print(np.sort(readouts[fails]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T00:29:26.147751Z",
     "start_time": "2020-10-16T00:29:08.361290Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 64 into shape (16,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-ca8873316b6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#c = ax.pcolor(thetas[i + j][1:].reshape(28, 28), cmap = 'gray')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfails\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gray_r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 64 into shape (16,16)"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, int(np.ceil(len(fails) / 3)), figsize=(15,9))\n",
    "count = 0\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(int(np.ceil(len(fails) / 3))):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        #c = ax.pcolor(thetas[i + j][1:].reshape(28, 28), cmap = 'gray')\n",
    "        try:\n",
    "            c = ax.imshow(np.array(X_test[fails[count]]).reshape(16, 16), cmap = 'gray_r', interpolation='nearest')\n",
    "            ax.axis('off')\n",
    "            ax.axis('equal')\n",
    "            ax.set_title(f'Classified as {classification[fails[count]]}').set_position([0.5, 1.1])\n",
    "            count += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.colorbar(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:10.983350Z",
     "start_time": "2020-10-16T02:34:10.979359Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({10: 1617, 9: 180})"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:11.390692Z",
     "start_time": "2020-10-16T02:34:11.386702Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22131348, 0.18847656, 0.34777832, ..., 0.16442871, 0.18591309,\n",
       "       0.19091797])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:11.719082Z",
     "start_time": "2020-10-16T02:34:11.715124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "indexes = [i for i in range(len(readouts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:12.117403Z",
     "start_time": "2020-10-16T02:34:12.075515Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 10, 0.2213134765625),\n",
       " (1, 10, 0.1884765625),\n",
       " (2, 10, 0.3477783203125),\n",
       " (3, 10, 0.247314453125),\n",
       " (4, 10, 0.174072265625),\n",
       " (5, 10, 0.1011962890625),\n",
       " (6, 10, 0.096435546875),\n",
       " (7, 10, 0.32373046875),\n",
       " (8, 10, 0.2769775390625),\n",
       " (9, 9, 0.1396484375),\n",
       " (10, 10, 0.22216796875),\n",
       " (11, 10, 0.193359375),\n",
       " (12, 10, 0.143310546875),\n",
       " (13, 10, 0.1663818359375),\n",
       " (14, 10, 0.2218017578125),\n",
       " (15, 10, 0.1964111328125),\n",
       " (16, 10, 0.190673828125),\n",
       " (17, 10, 0.2867431640625),\n",
       " (18, 10, 0.252685546875),\n",
       " (19, 9, 0.1409912109375),\n",
       " (20, 10, 0.3192138671875),\n",
       " (21, 10, 0.24072265625),\n",
       " (22, 10, 0.1644287109375),\n",
       " (23, 10, 0.314453125),\n",
       " (24, 10, 0.2559814453125),\n",
       " (25, 10, 0.0960693359375),\n",
       " (26, 10, 0.1400146484375),\n",
       " (27, 10, 0.3551025390625),\n",
       " (28, 10, 0.2484130859375),\n",
       " (29, 9, 0.08203125),\n",
       " (30, 10, 0.201904296875),\n",
       " (31, 9, 0.2232666015625),\n",
       " (32, 10, 0.16748046875),\n",
       " (33, 10, 0.1922607421875),\n",
       " (34, 10, 0.1851806640625),\n",
       " (35, 10, 0.1402587890625),\n",
       " (36, 10, 0.3587646484375),\n",
       " (37, 9, 0.0240478515625),\n",
       " (38, 10, 0.1446533203125),\n",
       " (39, 9, 0.270751953125),\n",
       " (40, 10, 0.189208984375),\n",
       " (41, 10, 0.1964111328125),\n",
       " (42, 10, 0.252685546875),\n",
       " (43, 10, 0.438232421875),\n",
       " (44, 10, 0.2786865234375),\n",
       " (45, 10, 0.1639404296875),\n",
       " (46, 10, 0.169189453125),\n",
       " (47, 10, 0.1884765625),\n",
       " (48, 10, 0.317138671875),\n",
       " (49, 10, 0.291748046875),\n",
       " (50, 10, 0.24951171875),\n",
       " (51, 10, 0.5120849609375),\n",
       " (52, 10, 0.4285888671875),\n",
       " (53, 10, 0.3914794921875),\n",
       " (54, 10, 0.3551025390625),\n",
       " (55, 10, 0.2794189453125),\n",
       " (56, 10, 0.2845458984375),\n",
       " (57, 10, 0.2840576171875),\n",
       " (58, 10, 0.0792236328125),\n",
       " (59, 10, 0.1915283203125),\n",
       " (60, 10, 0.217529296875),\n",
       " (61, 10, 0.4208984375),\n",
       " (62, 10, 0.19287109375),\n",
       " (63, 10, 0.2850341796875),\n",
       " (64, 10, 0.110595703125),\n",
       " (65, 10, 0.0966796875),\n",
       " (66, 10, 0.0616455078125),\n",
       " (67, 10, 0.1383056640625),\n",
       " (68, 10, 0.17041015625),\n",
       " (69, 9, 0.2427978515625),\n",
       " (70, 10, 0.1630859375),\n",
       " (71, 10, 0.1912841796875),\n",
       " (72, 10, 0.2855224609375),\n",
       " (73, 9, 0.1002197265625),\n",
       " (74, 10, 0.113525390625),\n",
       " (75, 10, 0.5206298828125),\n",
       " (76, 10, 0.22705078125),\n",
       " (77, 10, 0.3619384765625),\n",
       " (78, 10, 0.2152099609375),\n",
       " (79, 10, 0.2569580078125),\n",
       " (80, 10, 0.2432861328125),\n",
       " (81, 10, 0.4305419921875),\n",
       " (82, 10, 0.097900390625),\n",
       " (83, 10, 0.265380859375),\n",
       " (84, 10, 0.0501708984375),\n",
       " (85, 10, 0.2838134765625),\n",
       " (86, 10, 0.351806640625),\n",
       " (87, 10, 0.139892578125),\n",
       " (88, 10, 0.1416015625),\n",
       " (89, 10, 0.25),\n",
       " (90, 10, 0.312255859375),\n",
       " (91, 10, 0.2802734375),\n",
       " (92, 9, 0.3514404296875),\n",
       " (93, 10, 0.1673583984375),\n",
       " (94, 10, 0.3529052734375),\n",
       " (95, 10, 0.213134765625),\n",
       " (96, 10, 0.2515869140625),\n",
       " (97, 10, 0.189208984375),\n",
       " (98, 10, 0.3492431640625),\n",
       " (99, 10, 0.21875),\n",
       " (100, 10, 0.2506103515625),\n",
       " (101, 10, 0.2122802734375),\n",
       " (102, 10, 0.0821533203125),\n",
       " (103, 10, 0.3878173828125),\n",
       " (104, 10, 0.223388671875),\n",
       " (105, 9, 0.1954345703125),\n",
       " (106, 10, 0.1961669921875),\n",
       " (107, 10, 0.313232421875),\n",
       " (108, 10, 0.471923828125),\n",
       " (109, 10, 0.1617431640625),\n",
       " (110, 10, 0.2244873046875),\n",
       " (111, 10, 0.2227783203125),\n",
       " (112, 10, 0.479736328125),\n",
       " (113, 10, 0.1861572265625),\n",
       " (114, 10, 0.2828369140625),\n",
       " (115, 10, 0.465576171875),\n",
       " (116, 10, 0.3653564453125),\n",
       " (117, 10, 0.225830078125),\n",
       " (118, 10, 0.424560546875),\n",
       " (119, 9, 0.24951171875),\n",
       " (120, 10, 0.228759765625),\n",
       " (121, 10, 0.2210693359375),\n",
       " (122, 10, 0.3121337890625),\n",
       " (123, 10, 0.3125),\n",
       " (124, 10, 0.248779296875),\n",
       " (125, 9, 0.2550048828125),\n",
       " (126, 10, 0.3382568359375),\n",
       " (127, 10, 0.3570556640625),\n",
       " (128, 9, 0.2576904296875),\n",
       " (129, 10, 0.2821044921875),\n",
       " (130, 10, 0.1649169921875),\n",
       " (131, 10, 0.2813720703125),\n",
       " (132, 10, 0.117919921875),\n",
       " (133, 10, 0.3138427734375),\n",
       " (134, 10, 0.1690673828125),\n",
       " (135, 10, 0.170654296875),\n",
       " (136, 10, 0.115478515625),\n",
       " (137, 10, 0.510986328125),\n",
       " (138, 10, 0.1923828125),\n",
       " (139, 9, 0.142822265625),\n",
       " (140, 10, 0.2276611328125),\n",
       " (141, 10, 0.2467041015625),\n",
       " (142, 10, 0.1390380859375),\n",
       " (143, 10, 0.1956787109375),\n",
       " (144, 10, 0.14306640625),\n",
       " (145, 10, 0.25244140625),\n",
       " (146, 10, 0.138671875),\n",
       " (147, 10, 0.3543701171875),\n",
       " (148, 10, 0.19189453125),\n",
       " (149, 9, 0.2205810546875),\n",
       " (150, 10, 0.188232421875),\n",
       " (151, 10, 0.2213134765625),\n",
       " (152, 10, 0.385009765625),\n",
       " (153, 10, 0.2864990234375),\n",
       " (154, 10, 0.14111328125),\n",
       " (155, 10, 0.1190185546875),\n",
       " (156, 10, 0.1427001953125),\n",
       " (157, 10, 0.1856689453125),\n",
       " (158, 10, 0.3089599609375),\n",
       " (159, 9, 0.1634521484375),\n",
       " (160, 10, 0.35595703125),\n",
       " (161, 9, 0.2152099609375),\n",
       " (162, 10, 0.215576171875),\n",
       " (163, 10, 0.103271484375),\n",
       " (164, 10, 0.1199951171875),\n",
       " (165, 10, 0.1378173828125),\n",
       " (166, 10, 0.34716796875),\n",
       " (167, 9, 0.2723388671875),\n",
       " (168, 10, 0.216552734375),\n",
       " (169, 9, 0.1646728515625),\n",
       " (170, 10, 0.2177734375),\n",
       " (171, 10, 0.138671875),\n",
       " (172, 10, 0.283935546875),\n",
       " (173, 10, 0.511962890625),\n",
       " (174, 10, 0.3939208984375),\n",
       " (175, 10, 0.277099609375),\n",
       " (176, 10, 0.1663818359375),\n",
       " (177, 10, 0.219970703125),\n",
       " (178, 10, 0.22119140625),\n",
       " (179, 10, 0.252685546875),\n",
       " (180, 10, 0.098876953125),\n",
       " (181, 10, 0.1700439453125),\n",
       " (182, 10, 0.4403076171875),\n",
       " (183, 10, 0.211181640625),\n",
       " (184, 10, 0.1190185546875),\n",
       " (185, 10, 0.22607421875),\n",
       " (186, 10, 0.2198486328125),\n",
       " (187, 10, 0.117431640625),\n",
       " (188, 10, 0.076904296875),\n",
       " (189, 10, 0.2569580078125),\n",
       " (190, 10, 0.1373291015625),\n",
       " (191, 10, 0.218017578125),\n",
       " (192, 10, 0.314208984375),\n",
       " (193, 10, 0.21484375),\n",
       " (194, 10, 0.1907958984375),\n",
       " (195, 10, 0.1187744140625),\n",
       " (196, 10, 0.1214599609375),\n",
       " (197, 10, 0.1395263671875),\n",
       " (198, 10, 0.146728515625),\n",
       " (199, 9, 0.115478515625),\n",
       " (200, 10, 0.2896728515625),\n",
       " (201, 10, 0.16015625),\n",
       " (202, 10, 0.277099609375),\n",
       " (203, 9, 0.118408203125),\n",
       " (204, 10, 0.1380615234375),\n",
       " (205, 10, 0.3590087890625),\n",
       " (206, 10, 0.140380859375),\n",
       " (207, 10, 0.12060546875),\n",
       " (208, 10, 0.3385009765625),\n",
       " (209, 10, 0.191650390625),\n",
       " (210, 10, 0.2874755859375),\n",
       " (211, 10, 0.1964111328125),\n",
       " (212, 10, 0.1165771484375),\n",
       " (213, 10, 0.3455810546875),\n",
       " (214, 10, 0.0826416015625),\n",
       " (215, 10, 0.2451171875),\n",
       " (216, 10, 0.3201904296875),\n",
       " (217, 10, 0.3553466796875),\n",
       " (218, 10, 0.21435546875),\n",
       " (219, 10, 0.2503662109375),\n",
       " (220, 9, 0.094482421875),\n",
       " (221, 10, 0.193359375),\n",
       " (222, 10, 0.59912109375),\n",
       " (223, 10, 0.1138916015625),\n",
       " (224, 10, 0.316650390625),\n",
       " (225, 10, 0.166259765625),\n",
       " (226, 10, 0.438232421875),\n",
       " (227, 10, 0.1927490234375),\n",
       " (228, 10, 0.1220703125),\n",
       " (229, 10, 0.2864990234375),\n",
       " (230, 10, 0.165283203125),\n",
       " (231, 10, 0.4329833984375),\n",
       " (232, 10, 0.1600341796875),\n",
       " (233, 9, 0.144775390625),\n",
       " (234, 10, 0.16064453125),\n",
       " (235, 10, 0.2449951171875),\n",
       " (236, 10, 0.3448486328125),\n",
       " (237, 10, 0.1339111328125),\n",
       " (238, 10, 0.135498046875),\n",
       " (239, 10, 0.163818359375),\n",
       " (240, 10, 0.255126953125),\n",
       " (241, 10, 0.0823974609375),\n",
       " (242, 10, 0.3565673828125),\n",
       " (243, 10, 0.119140625),\n",
       " (244, 10, 0.141845703125),\n",
       " (245, 10, 0.1474609375),\n",
       " (246, 10, 0.1177978515625),\n",
       " (247, 10, 0.1634521484375),\n",
       " (248, 10, 0.3216552734375),\n",
       " (249, 10, 0.31103515625),\n",
       " (250, 10, 0.0958251953125),\n",
       " (251, 9, 0.24853515625),\n",
       " (252, 10, 0.2513427734375),\n",
       " (253, 10, 0.388916015625),\n",
       " (254, 9, 0.16796875),\n",
       " (255, 10, 0.24462890625),\n",
       " (256, 10, 0.28271484375),\n",
       " (257, 10, 0.322021484375),\n",
       " (258, 10, 0.1190185546875),\n",
       " (259, 10, 0.1905517578125),\n",
       " (260, 10, 0.245361328125),\n",
       " (261, 10, 0.163818359375),\n",
       " (262, 10, 0.1656494140625),\n",
       " (263, 10, 0.3568115234375),\n",
       " (264, 10, 0.1397705078125),\n",
       " (265, 9, 0.2835693359375),\n",
       " (266, 10, 0.1900634765625),\n",
       " (267, 10, 0.1898193359375),\n",
       " (268, 10, 0.092041015625),\n",
       " (269, 10, 0.2171630859375),\n",
       " (270, 10, 0.220947265625),\n",
       " (271, 10, 0.312255859375),\n",
       " (272, 10, 0.165771484375),\n",
       " (273, 10, 0.3951416015625),\n",
       " (274, 10, 0.187744140625),\n",
       " (275, 9, 0.31787109375),\n",
       " (276, 10, 0.2451171875),\n",
       " (277, 10, 0.25341796875),\n",
       " (278, 10, 0.1956787109375),\n",
       " (279, 10, 0.191162109375),\n",
       " (280, 10, 0.281494140625),\n",
       " (281, 10, 0.0938720703125),\n",
       " (282, 10, 0.1177978515625),\n",
       " (283, 10, 0.4635009765625),\n",
       " (284, 10, 0.3052978515625),\n",
       " (285, 9, 0.2823486328125),\n",
       " (286, 10, 0.24658203125),\n",
       " (287, 9, 0.1888427734375),\n",
       " (288, 10, 0.139892578125),\n",
       " (289, 10, 0.0914306640625),\n",
       " (290, 10, 0.117431640625),\n",
       " (291, 10, 0.058837890625),\n",
       " (292, 10, 0.18701171875),\n",
       " (293, 9, 0.192138671875),\n",
       " (294, 10, 0.311767578125),\n",
       " (295, 9, 0.2178955078125),\n",
       " (296, 10, 0.2801513671875),\n",
       " (297, 10, 0.2247314453125),\n",
       " (298, 10, 0.16943359375),\n",
       " (299, 10, 0.348876953125),\n",
       " (300, 10, 0.4268798828125),\n",
       " (301, 10, 0.2171630859375),\n",
       " (302, 10, 0.140380859375),\n",
       " (303, 10, 0.1978759765625),\n",
       " (304, 10, 0.256591796875),\n",
       " (305, 10, 0.25634765625),\n",
       " (306, 10, 0.0601806640625),\n",
       " (307, 10, 0.2547607421875),\n",
       " (308, 10, 0.5650634765625),\n",
       " (309, 10, 0.25048828125),\n",
       " (310, 10, 0.19482421875),\n",
       " (311, 10, 0.3236083984375),\n",
       " (312, 10, 0.3187255859375),\n",
       " (313, 10, 0.1185302734375),\n",
       " (314, 10, 0.2218017578125),\n",
       " (315, 10, 0.06689453125),\n",
       " (316, 10, 0.2509765625),\n",
       " (317, 10, 0.425048828125),\n",
       " (318, 10, 0.12060546875),\n",
       " (319, 10, 0.120849609375),\n",
       " (320, 10, 0.188720703125),\n",
       " (321, 10, 0.141845703125),\n",
       " (322, 10, 0.120849609375),\n",
       " (323, 10, 0.096435546875),\n",
       " (324, 10, 0.242919921875),\n",
       " (325, 9, 0.35595703125),\n",
       " (326, 10, 0.311767578125),\n",
       " (327, 10, 0.1566162109375),\n",
       " (328, 10, 0.15771484375),\n",
       " (329, 9, 0.3980712890625),\n",
       " (330, 10, 0.1456298828125),\n",
       " (331, 10, 0.0938720703125),\n",
       " (332, 10, 0.1669921875),\n",
       " (333, 10, 0.1429443359375),\n",
       " (334, 10, 0.3187255859375),\n",
       " (335, 10, 0.1676025390625),\n",
       " (336, 10, 0.2841796875),\n",
       " (337, 10, 0.3916015625),\n",
       " (338, 10, 0.1422119140625),\n",
       " (339, 10, 0.161376953125),\n",
       " (340, 10, 0.1884765625),\n",
       " (341, 10, 0.20947265625),\n",
       " (342, 10, 0.5181884765625),\n",
       " (343, 10, 0.2208251953125),\n",
       " (344, 10, 0.1339111328125),\n",
       " (345, 10, 0.2535400390625),\n",
       " (346, 10, 0.2454833984375),\n",
       " (347, 10, 0.138916015625),\n",
       " (348, 9, 0.3492431640625),\n",
       " (349, 10, 0.2232666015625),\n",
       " (350, 10, 0.281982421875),\n",
       " (351, 10, 0.16015625),\n",
       " (352, 10, 0.195556640625),\n",
       " (353, 10, 0.2193603515625),\n",
       " (354, 10, 0.1165771484375),\n",
       " (355, 10, 0.2752685546875),\n",
       " (356, 10, 0.2548828125),\n",
       " (357, 10, 0.2803955078125),\n",
       " (358, 10, 0.1429443359375),\n",
       " (359, 10, 0.2105712890625),\n",
       " (360, 10, 0.1385498046875),\n",
       " (361, 9, 0.390625),\n",
       " (362, 10, 0.1981201171875),\n",
       " (363, 10, 0.191650390625),\n",
       " (364, 10, 0.193359375),\n",
       " (365, 10, 0.100341796875),\n",
       " (366, 10, 0.191162109375),\n",
       " (367, 10, 0.169189453125),\n",
       " (368, 10, 0.465087890625),\n",
       " (369, 10, 0.1402587890625),\n",
       " (370, 10, 0.2540283203125),\n",
       " (371, 10, 0.0966796875),\n",
       " (372, 10, 0.0933837890625),\n",
       " (373, 10, 0.14404296875),\n",
       " (374, 10, 0.430908203125),\n",
       " (375, 9, 0.189453125),\n",
       " (376, 10, 0.117919921875),\n",
       " (377, 10, 0.2579345703125),\n",
       " (378, 10, 0.224609375),\n",
       " (379, 10, 0.2691650390625),\n",
       " (380, 10, 0.1927490234375),\n",
       " (381, 9, 0.142333984375),\n",
       " (382, 10, 0.26416015625),\n",
       " (383, 10, 0.358642578125),\n",
       " (384, 9, 0.289306640625),\n",
       " (385, 10, 0.2254638671875),\n",
       " (386, 10, 0.212890625),\n",
       " (387, 10, 0.249755859375),\n",
       " (388, 10, 0.1400146484375),\n",
       " (389, 10, 0.319580078125),\n",
       " (390, 10, 0.1678466796875),\n",
       " (391, 10, 0.213623046875),\n",
       " (392, 10, 0.188720703125),\n",
       " (393, 10, 0.469970703125),\n",
       " (394, 10, 0.256591796875),\n",
       " (395, 9, 0.24609375),\n",
       " (396, 10, 0.319580078125),\n",
       " (397, 10, 0.2115478515625),\n",
       " (398, 10, 0.1854248046875),\n",
       " (399, 10, 0.13623046875),\n",
       " (400, 10, 0.1600341796875),\n",
       " (401, 10, 0.216796875),\n",
       " (402, 10, 0.1824951171875),\n",
       " (403, 10, 0.352783203125),\n",
       " (404, 10, 0.220458984375),\n",
       " (405, 9, 0.2476806640625),\n",
       " (406, 10, 0.277099609375),\n",
       " (407, 10, 0.2152099609375),\n",
       " (408, 10, 0.0894775390625),\n",
       " (409, 10, 0.3499755859375),\n",
       " (410, 10, 0.1605224609375),\n",
       " (411, 10, 0.240478515625),\n",
       " (412, 10, 0.1656494140625),\n",
       " (413, 10, 0.3458251953125),\n",
       " (414, 10, 0.22607421875),\n",
       " (415, 9, 0.248046875),\n",
       " (416, 10, 0.3487548828125),\n",
       " (417, 9, 0.211181640625),\n",
       " (418, 10, 0.1416015625),\n",
       " (419, 10, 0.2193603515625),\n",
       " (420, 10, 0.172607421875),\n",
       " (421, 10, 0.3216552734375),\n",
       " (422, 10, 0.2261962890625),\n",
       " (423, 9, 0.1649169921875),\n",
       " (424, 10, 0.2525634765625),\n",
       " (425, 9, 0.2464599609375),\n",
       " (426, 10, 0.2178955078125),\n",
       " (427, 10, 0.2803955078125),\n",
       " (428, 10, 0.249755859375),\n",
       " (429, 10, 0.3876953125),\n",
       " (430, 10, 0.3909912109375),\n",
       " (431, 10, 0.1881103515625),\n",
       " (432, 10, 0.2152099609375),\n",
       " (433, 10, 0.14306640625),\n",
       " (434, 10, 0.3184814453125),\n",
       " (435, 10, 0.167724609375),\n",
       " (436, 10, 0.1197509765625),\n",
       " (437, 10, 0.1884765625),\n",
       " (438, 10, 0.51220703125),\n",
       " (439, 10, 0.1884765625),\n",
       " (440, 10, 0.1669921875),\n",
       " (441, 10, 0.355224609375),\n",
       " (442, 10, 0.195556640625),\n",
       " (443, 10, 0.250732421875),\n",
       " (444, 10, 0.2821044921875),\n",
       " (445, 10, 0.219482421875),\n",
       " (446, 10, 0.197509765625),\n",
       " (447, 10, 0.27294921875),\n",
       " (448, 10, 0.2529296875),\n",
       " (449, 10, 0.138427734375),\n",
       " (450, 10, 0.1650390625),\n",
       " (451, 10, 0.0947265625),\n",
       " (452, 10, 0.0948486328125),\n",
       " (453, 10, 0.119873046875),\n",
       " (454, 10, 0.1605224609375),\n",
       " (455, 9, 0.22021484375),\n",
       " (456, 10, 0.2789306640625),\n",
       " (457, 10, 0.12353515625),\n",
       " (458, 10, 0.2801513671875),\n",
       " (459, 9, 0.313720703125),\n",
       " (460, 10, 0.16796875),\n",
       " (461, 10, 0.20263671875),\n",
       " (462, 10, 0.2237548828125),\n",
       " (463, 10, 0.0963134765625),\n",
       " (464, 10, 0.253173828125),\n",
       " (465, 10, 0.1927490234375),\n",
       " (466, 10, 0.117919921875),\n",
       " (467, 10, 0.3505859375),\n",
       " (468, 10, 0.2457275390625),\n",
       " (469, 10, 0.1627197265625),\n",
       " (470, 10, 0.06103515625),\n",
       " (471, 10, 0.095947265625),\n",
       " (472, 10, 0.51806640625),\n",
       " (473, 10, 0.355224609375),\n",
       " (474, 10, 0.0806884765625),\n",
       " (475, 10, 0.27587890625),\n",
       " (476, 10, 0.2196044921875),\n",
       " (477, 10, 0.164306640625),\n",
       " (478, 9, 0.1416015625),\n",
       " (479, 10, 0.1629638671875),\n",
       " (480, 10, 0.345458984375),\n",
       " (481, 10, 0.16943359375),\n",
       " (482, 10, 0.3135986328125),\n",
       " (483, 10, 0.2593994140625),\n",
       " (484, 10, 0.0958251953125),\n",
       " (485, 10, 0.140380859375),\n",
       " (486, 10, 0.171142578125),\n",
       " (487, 10, 0.23095703125),\n",
       " (488, 10, 0.194580078125),\n",
       " (489, 10, 0.2535400390625),\n",
       " (490, 10, 0.16455078125),\n",
       " (491, 9, 0.1904296875),\n",
       " (492, 10, 0.312255859375),\n",
       " (493, 10, 0.212890625),\n",
       " (494, 10, 0.3594970703125),\n",
       " (495, 10, 0.1451416015625),\n",
       " (496, 10, 0.213623046875),\n",
       " (497, 10, 0.2261962890625),\n",
       " (498, 10, 0.316650390625),\n",
       " (499, 10, 0.02490234375),\n",
       " (500, 10, 0.2474365234375),\n",
       " (501, 10, 0.09814453125),\n",
       " (502, 10, 0.31884765625),\n",
       " (503, 10, 0.1593017578125),\n",
       " (504, 10, 0.3509521484375),\n",
       " (505, 9, 0.2886962890625),\n",
       " (506, 10, 0.1461181640625),\n",
       " (507, 10, 0.2437744140625),\n",
       " (508, 10, 0.1832275390625),\n",
       " (509, 10, 0.325439453125),\n",
       " (510, 10, 0.191162109375),\n",
       " (511, 9, 0.315185546875),\n",
       " (512, 10, 0.28076171875),\n",
       " (513, 10, 0.251220703125),\n",
       " (514, 9, 0.2178955078125),\n",
       " (515, 10, 0.3260498046875),\n",
       " (516, 10, 0.2843017578125),\n",
       " (517, 10, 0.0972900390625),\n",
       " (518, 10, 0.3250732421875),\n",
       " (519, 10, 0.1915283203125),\n",
       " (520, 10, 0.225830078125),\n",
       " (521, 10, 0.162109375),\n",
       " (522, 10, 0.21728515625),\n",
       " (523, 10, 0.184814453125),\n",
       " (524, 10, 0.3092041015625),\n",
       " (525, 9, 0.1932373046875),\n",
       " (526, 10, 0.2601318359375),\n",
       " (527, 10, 0.1641845703125),\n",
       " (528, 10, 0.0772705078125),\n",
       " (529, 10, 0.2216796875),\n",
       " (530, 10, 0.1671142578125),\n",
       " (531, 10, 0.1380615234375),\n",
       " (532, 10, 0.1884765625),\n",
       " (533, 10, 0.3192138671875),\n",
       " (534, 10, 0.280517578125),\n",
       " (535, 9, 0.2476806640625),\n",
       " (536, 10, 0.4368896484375),\n",
       " (537, 10, 0.193603515625),\n",
       " (538, 10, 0.0968017578125),\n",
       " (539, 10, 0.1151123046875),\n",
       " (540, 10, 0.1839599609375),\n",
       " (541, 10, 0.1884765625),\n",
       " (542, 10, 0.14404296875),\n",
       " (543, 10, 0.5626220703125),\n",
       " (544, 10, 0.2239990234375),\n",
       " (545, 9, 0.1986083984375),\n",
       " (546, 10, 0.355224609375),\n",
       " (547, 9, 0.3160400390625),\n",
       " (548, 10, 0.12451171875),\n",
       " (549, 10, 0.1605224609375),\n",
       " (550, 10, 0.156005859375),\n",
       " (551, 10, 0.2135009765625),\n",
       " (552, 10, 0.341796875),\n",
       " (553, 9, 0.219482421875),\n",
       " (554, 10, 0.2427978515625),\n",
       " (555, 9, 0.3433837890625),\n",
       " (556, 10, 0.2225341796875),\n",
       " (557, 10, 0.241455078125),\n",
       " (558, 10, 0.081298828125),\n",
       " (559, 10, 0.3902587890625),\n",
       " (560, 10, 0.4351806640625),\n",
       " (561, 10, 0.2156982421875),\n",
       " (562, 10, 0.115966796875),\n",
       " (563, 10, 0.1651611328125),\n",
       " (564, 10, 0.2783203125),\n",
       " (565, 10, 0.1455078125),\n",
       " (566, 10, 0.1964111328125),\n",
       " (567, 10, 0.1663818359375),\n",
       " (568, 10, 0.2569580078125),\n",
       " (569, 10, 0.224609375),\n",
       " (570, 10, 0.220458984375),\n",
       " (571, 10, 0.31884765625),\n",
       " (572, 10, 0.0631103515625),\n",
       " (573, 10, 0.148681640625),\n",
       " (574, 10, 0.2459716796875),\n",
       " (575, 10, 0.0970458984375),\n",
       " (576, 10, 0.3133544921875),\n",
       " (577, 10, 0.5164794921875),\n",
       " (578, 10, 0.221435546875),\n",
       " (579, 10, 0.1510009765625),\n",
       " (580, 10, 0.3104248046875),\n",
       " (581, 10, 0.117431640625),\n",
       " (582, 10, 0.14013671875),\n",
       " (583, 10, 0.19140625),\n",
       " (584, 10, 0.15966796875),\n",
       " (585, 9, 0.189208984375),\n",
       " (586, 10, 0.0750732421875),\n",
       " (587, 10, 0.1368408203125),\n",
       " (588, 10, 0.2530517578125),\n",
       " (589, 9, 0.189697265625),\n",
       " (590, 10, 0.2236328125),\n",
       " (591, 10, 0.0947265625),\n",
       " (592, 10, 0.2520751953125),\n",
       " (593, 10, 0.095947265625),\n",
       " (594, 10, 0.3843994140625),\n",
       " (595, 10, 0.3231201171875),\n",
       " (596, 10, 0.1651611328125),\n",
       " (597, 10, 0.251220703125),\n",
       " (598, 10, 0.1162109375),\n",
       " (599, 10, 0.1165771484375),\n",
       " (600, 10, 0.099365234375),\n",
       " (601, 10, 0.0599365234375),\n",
       " (602, 10, 0.42822265625),\n",
       " (603, 10, 0.25),\n",
       " (604, 10, 0.2183837890625),\n",
       " (605, 10, 0.168701171875),\n",
       " (606, 10, 0.1405029296875),\n",
       " (607, 10, 0.1700439453125),\n",
       " (608, 9, 0.2166748046875),\n",
       " (609, 10, 0.08154296875),\n",
       " (610, 10, 0.421142578125),\n",
       " (611, 10, 0.1396484375),\n",
       " (612, 10, 0.1873779296875),\n",
       " (613, 10, 0.2186279296875),\n",
       " (614, 10, 0.189697265625),\n",
       " (615, 10, 0.163330078125),\n",
       " (616, 10, 0.279052734375),\n",
       " (617, 10, 0.42626953125),\n",
       " (618, 10, 0.1915283203125),\n",
       " (619, 10, 0.1915283203125),\n",
       " (620, 10, 0.14306640625),\n",
       " (621, 9, 0.214111328125),\n",
       " (622, 10, 0.2235107421875),\n",
       " (623, 10, 0.1451416015625),\n",
       " (624, 10, 0.4248046875),\n",
       " (625, 10, 0.0941162109375),\n",
       " (626, 10, 0.3172607421875),\n",
       " (627, 10, 0.2503662109375),\n",
       " (628, 10, 0.166748046875),\n",
       " (629, 10, 0.064453125),\n",
       " (630, 10, 0.189208984375),\n",
       " (631, 10, 0.1151123046875),\n",
       " (632, 10, 0.125244140625),\n",
       " (633, 10, 0.1429443359375),\n",
       " (634, 10, 0.32275390625),\n",
       " (635, 9, 0.2220458984375),\n",
       " (636, 10, 0.099609375),\n",
       " (637, 10, 0.159912109375),\n",
       " (638, 10, 0.2830810546875),\n",
       " (639, 10, 0.278564453125),\n",
       " (640, 10, 0.2860107421875),\n",
       " (641, 9, 0.2840576171875),\n",
       " (642, 10, 0.3564453125),\n",
       " (643, 10, 0.2738037109375),\n",
       " (644, 9, 0.191650390625),\n",
       " (645, 10, 0.316162109375),\n",
       " (646, 10, 0.1715087890625),\n",
       " (647, 10, 0.3026123046875),\n",
       " (648, 10, 0.0770263671875),\n",
       " (649, 10, 0.2255859375),\n",
       " (650, 10, 0.1680908203125),\n",
       " (651, 10, 0.1641845703125),\n",
       " (652, 10, 0.1666259765625),\n",
       " (653, 10, 0.3245849609375),\n",
       " (654, 10, 0.1875),\n",
       " (655, 9, 0.13818359375),\n",
       " (656, 10, 0.362548828125),\n",
       " (657, 10, 0.1673583984375),\n",
       " (658, 10, 0.079833984375),\n",
       " (659, 10, 0.1378173828125),\n",
       " (660, 10, 0.1204833984375),\n",
       " (661, 10, 0.1209716796875),\n",
       " (662, 10, 0.1893310546875),\n",
       " (663, 10, 0.349365234375),\n",
       " (664, 10, 0.1895751953125),\n",
       " (665, 9, 0.123046875),\n",
       " (666, 10, 0.2176513671875),\n",
       " (667, 10, 0.1429443359375),\n",
       " (668, 10, 0.287841796875),\n",
       " (669, 10, 0.144775390625),\n",
       " (670, 10, 0.3565673828125),\n",
       " (671, 10, 0.1231689453125),\n",
       " (672, 10, 0.2152099609375),\n",
       " (673, 10, 0.18603515625),\n",
       " (674, 10, 0.2470703125),\n",
       " (675, 9, 0.1629638671875),\n",
       " (676, 10, 0.21484375),\n",
       " (677, 9, 0.185791015625),\n",
       " (678, 10, 0.1954345703125),\n",
       " (679, 10, 0.1734619140625),\n",
       " (680, 10, 0.138916015625),\n",
       " (681, 10, 0.218017578125),\n",
       " (682, 10, 0.282958984375),\n",
       " (683, 9, 0.2216796875),\n",
       " (684, 10, 0.1923828125),\n",
       " (685, 9, 0.2235107421875),\n",
       " (686, 10, 0.1734619140625),\n",
       " (687, 10, 0.2811279296875),\n",
       " (688, 10, 0.391845703125),\n",
       " (689, 10, 0.2447509765625),\n",
       " (690, 10, 0.2796630859375),\n",
       " (691, 10, 0.224609375),\n",
       " (692, 10, 0.200439453125),\n",
       " (693, 10, 0.398193359375),\n",
       " (694, 10, 0.3187255859375),\n",
       " (695, 10, 0.302490234375),\n",
       " (696, 10, 0.2786865234375),\n",
       " (697, 10, 0.140625),\n",
       " (698, 10, 0.4002685546875),\n",
       " (699, 10, 0.19287109375),\n",
       " (700, 10, 0.2216796875),\n",
       " (701, 10, 0.2825927734375),\n",
       " (702, 10, 0.351318359375),\n",
       " (703, 10, 0.2496337890625),\n",
       " (704, 10, 0.1197509765625),\n",
       " (705, 10, 0.3221435546875),\n",
       " (706, 10, 0.1943359375),\n",
       " (707, 10, 0.42529296875),\n",
       " (708, 10, 0.3470458984375),\n",
       " (709, 10, 0.1468505859375),\n",
       " (710, 10, 0.19091796875),\n",
       " (711, 10, 0.1156005859375),\n",
       " (712, 10, 0.1632080078125),\n",
       " (713, 10, 0.1226806640625),\n",
       " (714, 10, 0.1636962890625),\n",
       " (715, 9, 0.1845703125),\n",
       " (716, 10, 0.145263671875),\n",
       " (717, 10, 0.0947265625),\n",
       " (718, 10, 0.3492431640625),\n",
       " (719, 9, 0.1912841796875),\n",
       " (720, 10, 0.2178955078125),\n",
       " (721, 10, 0.217041015625),\n",
       " (722, 10, 0.27197265625),\n",
       " (723, 10, 0.0792236328125),\n",
       " (724, 10, 0.2801513671875),\n",
       " (725, 10, 0.2254638671875),\n",
       " (726, 10, 0.3529052734375),\n",
       " (727, 10, 0.3486328125),\n",
       " (728, 10, 0.1607666015625),\n",
       " (729, 10, 0.28466796875),\n",
       " (730, 10, 0.1385498046875),\n",
       " (731, 10, 0.2481689453125),\n",
       " (732, 10, 0.2237548828125),\n",
       " (733, 10, 0.164794921875),\n",
       " (734, 10, 0.076416015625),\n",
       " (735, 10, 0.1424560546875),\n",
       " (736, 10, 0.1910400390625),\n",
       " (737, 10, 0.2186279296875),\n",
       " (738, 9, 0.2242431640625),\n",
       " (739, 10, 0.21923828125),\n",
       " (740, 10, 0.34375),\n",
       " (741, 10, 0.137939453125),\n",
       " (742, 10, 0.1875),\n",
       " (743, 10, 0.31494140625),\n",
       " (744, 10, 0.1893310546875),\n",
       " (745, 10, 0.173095703125),\n",
       " (746, 10, 0.16748046875),\n",
       " (747, 10, 0.2232666015625),\n",
       " (748, 10, 0.07861328125),\n",
       " (749, 10, 0.096923828125),\n",
       " (750, 10, 0.117431640625),\n",
       " (751, 9, 0.13916015625),\n",
       " (752, 10, 0.1575927734375),\n",
       " (753, 10, 0.38427734375),\n",
       " (754, 10, 0.353759765625),\n",
       " (755, 10, 0.1424560546875),\n",
       " (756, 10, 0.2156982421875),\n",
       " (757, 10, 0.1424560546875),\n",
       " (758, 10, 0.4278564453125),\n",
       " (759, 10, 0.1949462890625),\n",
       " (760, 10, 0.19287109375),\n",
       " (761, 10, 0.2498779296875),\n",
       " (762, 10, 0.1561279296875),\n",
       " (763, 10, 0.141357421875),\n",
       " (764, 10, 0.4755859375),\n",
       " (765, 9, 0.075439453125),\n",
       " (766, 10, 0.078857421875),\n",
       " (767, 10, 0.2882080078125),\n",
       " (768, 10, 0.2142333984375),\n",
       " (769, 10, 0.1361083984375),\n",
       " (770, 10, 0.2213134765625),\n",
       " (771, 9, 0.2191162109375),\n",
       " (772, 10, 0.2442626953125),\n",
       " (773, 10, 0.1444091796875),\n",
       " (774, 9, 0.2178955078125),\n",
       " (775, 10, 0.1888427734375),\n",
       " (776, 10, 0.2152099609375),\n",
       " (777, 10, 0.2509765625),\n",
       " (778, 10, 0.1552734375),\n",
       " (779, 10, 0.2261962890625),\n",
       " (780, 10, 0.1881103515625),\n",
       " (781, 10, 0.224853515625),\n",
       " (782, 10, 0.1627197265625),\n",
       " (783, 10, 0.4771728515625),\n",
       " (784, 10, 0.0631103515625),\n",
       " (785, 9, 0.146728515625),\n",
       " (786, 10, 0.16845703125),\n",
       " (787, 10, 0.286865234375),\n",
       " (788, 10, 0.095703125),\n",
       " (789, 10, 0.18896484375),\n",
       " (790, 10, 0.1856689453125),\n",
       " (791, 10, 0.1572265625),\n",
       " (792, 10, 0.1357421875),\n",
       " (793, 10, 0.391845703125),\n",
       " (794, 10, 0.136962890625),\n",
       " (795, 9, 0.1605224609375),\n",
       " (796, 10, 0.2236328125),\n",
       " (797, 10, 0.2857666015625),\n",
       " (798, 10, 0.0794677734375),\n",
       " (799, 10, 0.22216796875),\n",
       " (800, 10, 0.2177734375),\n",
       " (801, 10, 0.101806640625),\n",
       " (802, 10, 0.1656494140625),\n",
       " (803, 10, 0.3504638671875),\n",
       " (804, 10, 0.2918701171875),\n",
       " (805, 9, 0.1639404296875),\n",
       " (806, 10, 0.2139892578125),\n",
       " (807, 9, 0.213134765625),\n",
       " (808, 10, 0.2750244140625),\n",
       " (809, 10, 0.16064453125),\n",
       " (810, 10, 0.1231689453125),\n",
       " (811, 10, 0.160888671875),\n",
       " (812, 10, 0.22119140625),\n",
       " (813, 9, 0.14892578125),\n",
       " (814, 10, 0.124267578125),\n",
       " (815, 9, 0.1953125),\n",
       " (816, 10, 0.3106689453125),\n",
       " (817, 10, 0.1689453125),\n",
       " (818, 10, 0.1883544921875),\n",
       " (819, 10, 0.1962890625),\n",
       " (820, 10, 0.5596923828125),\n",
       " (821, 10, 0.187744140625),\n",
       " (822, 10, 0.2220458984375),\n",
       " (823, 10, 0.1912841796875),\n",
       " (824, 10, 0.2821044921875),\n",
       " (825, 10, 0.2791748046875),\n",
       " (826, 10, 0.162353515625),\n",
       " (827, 10, 0.1153564453125),\n",
       " (828, 10, 0.117919921875),\n",
       " (829, 10, 0.343994140625),\n",
       " (830, 10, 0.1175537109375),\n",
       " (831, 10, 0.31494140625),\n",
       " (832, 10, 0.04248046875),\n",
       " (833, 10, 0.079345703125),\n",
       " (834, 10, 0.1187744140625),\n",
       " (835, 10, 0.220947265625),\n",
       " (836, 10, 0.1458740234375),\n",
       " (837, 10, 0.5205078125),\n",
       " (838, 10, 0.277587890625),\n",
       " (839, 10, 0.3135986328125),\n",
       " (840, 10, 0.1942138671875),\n",
       " (841, 10, 0.1383056640625),\n",
       " (842, 10, 0.0972900390625),\n",
       " (843, 10, 0.1953125),\n",
       " (844, 10, 0.165771484375),\n",
       " (845, 9, 0.1356201171875),\n",
       " (846, 10, 0.431396484375),\n",
       " (847, 10, 0.3897705078125),\n",
       " (848, 10, 0.3841552734375),\n",
       " (849, 9, 0.165283203125),\n",
       " (850, 10, 0.1871337890625),\n",
       " (851, 10, 0.1475830078125),\n",
       " (852, 10, 0.193115234375),\n",
       " (853, 10, 0.1207275390625),\n",
       " (854, 10, 0.3897705078125),\n",
       " (855, 10, 0.22021484375),\n",
       " (856, 10, 0.1392822265625),\n",
       " (857, 10, 0.31494140625),\n",
       " (858, 10, 0.1932373046875),\n",
       " (859, 10, 0.2802734375),\n",
       " (860, 10, 0.3447265625),\n",
       " (861, 10, 0.36083984375),\n",
       " (862, 10, 0.515869140625),\n",
       " (863, 10, 0.140625),\n",
       " (864, 10, 0.1611328125),\n",
       " (865, 10, 0.13623046875),\n",
       " (866, 10, 0.286376953125),\n",
       " (867, 10, 0.1954345703125),\n",
       " (868, 9, 0.1707763671875),\n",
       " (869, 10, 0.2193603515625),\n",
       " (870, 10, 0.2186279296875),\n",
       " (871, 10, 0.143310546875),\n",
       " (872, 10, 0.11328125),\n",
       " (873, 10, 0.13818359375),\n",
       " (874, 10, 0.2523193359375),\n",
       " (875, 10, 0.254150390625),\n",
       " (876, 10, 0.27392578125),\n",
       " (877, 10, 0.169921875),\n",
       " (878, 10, 0.2215576171875),\n",
       " (879, 10, 0.185302734375),\n",
       " (880, 10, 0.138916015625),\n",
       " (881, 9, 0.2137451171875),\n",
       " (882, 10, 0.1348876953125),\n",
       " (883, 10, 0.3878173828125),\n",
       " (884, 10, 0.3143310546875),\n",
       " (885, 10, 0.119140625),\n",
       " (886, 10, 0.2159423828125),\n",
       " (887, 10, 0.1705322265625),\n",
       " (888, 10, 0.474365234375),\n",
       " (889, 10, 0.0965576171875),\n",
       " (890, 10, 0.21875),\n",
       " (891, 10, 0.510009765625),\n",
       " (892, 10, 0.1182861328125),\n",
       " (893, 10, 0.2559814453125),\n",
       " (894, 10, 0.2784423828125),\n",
       " (895, 9, 0.2403564453125),\n",
       " (896, 10, 0.1385498046875),\n",
       " (897, 10, 0.1673583984375),\n",
       " (898, 10, 0.214111328125),\n",
       " (899, 10, 0.1654052734375),\n",
       " (900, 10, 0.1732177734375),\n",
       " (901, 9, 0.3167724609375),\n",
       " (902, 10, 0.38720703125),\n",
       " (903, 10, 0.1187744140625),\n",
       " (904, 9, 0.2222900390625),\n",
       " (905, 10, 0.0938720703125),\n",
       " (906, 10, 0.0797119140625),\n",
       " (907, 10, 0.140625),\n",
       " (908, 10, 0.2801513671875),\n",
       " (909, 10, 0.146240234375),\n",
       " (910, 10, 0.0843505859375),\n",
       " (911, 10, 0.1708984375),\n",
       " (912, 10, 0.51025390625),\n",
       " (913, 10, 0.1883544921875),\n",
       " (914, 9, 0.16845703125),\n",
       " (915, 10, 0.242919921875),\n",
       " (916, 10, 0.049560546875),\n",
       " (917, 10, 0.103515625),\n",
       " (918, 10, 0.209228515625),\n",
       " (919, 10, 0.0782470703125),\n",
       " (920, 10, 0.1719970703125),\n",
       " (921, 10, 0.195556640625),\n",
       " (922, 10, 0.39111328125),\n",
       " (923, 10, 0.134033203125),\n",
       " (924, 9, 0.2210693359375),\n",
       " (925, 10, 0.24853515625),\n",
       " (926, 10, 0.08203125),\n",
       " (927, 10, 0.12060546875),\n",
       " (928, 10, 0.1907958984375),\n",
       " (929, 10, 0.095947265625),\n",
       " (930, 10, 0.1405029296875),\n",
       " (931, 10, 0.1611328125),\n",
       " (932, 10, 0.4283447265625),\n",
       " (933, 10, 0.132080078125),\n",
       " (934, 9, 0.1397705078125),\n",
       " (935, 10, 0.254638671875),\n",
       " (936, 9, 0.219970703125),\n",
       " (937, 10, 0.0980224609375),\n",
       " (938, 10, 0.1357421875),\n",
       " (939, 10, 0.172119140625),\n",
       " (940, 10, 0.1444091796875),\n",
       " (941, 10, 0.27587890625),\n",
       " (942, 9, 0.2452392578125),\n",
       " (943, 10, 0.2236328125),\n",
       " (944, 9, 0.2174072265625),\n",
       " (945, 10, 0.220703125),\n",
       " (946, 10, 0.094970703125),\n",
       " (947, 10, 0.1025390625),\n",
       " (948, 10, 0.351806640625),\n",
       " (949, 10, 0.5205078125),\n",
       " (950, 10, 0.139892578125),\n",
       " (951, 10, 0.1160888671875),\n",
       " (952, 10, 0.0972900390625),\n",
       " (953, 10, 0.0950927734375),\n",
       " (954, 10, 0.3492431640625),\n",
       " (955, 10, 0.1893310546875),\n",
       " (956, 10, 0.1646728515625),\n",
       " (957, 10, 0.284423828125),\n",
       " (958, 10, 0.1173095703125),\n",
       " (959, 10, 0.1165771484375),\n",
       " (960, 10, 0.1632080078125),\n",
       " (961, 10, 0.2216796875),\n",
       " (962, 10, 0.156494140625),\n",
       " (963, 10, 0.3946533203125),\n",
       " (964, 10, 0.3514404296875),\n",
       " (965, 10, 0.1846923828125),\n",
       " (966, 10, 0.0970458984375),\n",
       " (967, 10, 0.1016845703125),\n",
       " (968, 10, 0.165283203125),\n",
       " (969, 10, 0.0943603515625),\n",
       " (970, 10, 0.14697265625),\n",
       " (971, 9, 0.14013671875),\n",
       " (972, 10, 0.098876953125),\n",
       " (973, 10, 0.1654052734375),\n",
       " (974, 10, 0.3267822265625),\n",
       " (975, 9, 0.1669921875),\n",
       " (976, 10, 0.08251953125),\n",
       " (977, 10, 0.1903076171875),\n",
       " (978, 10, 0.311279296875),\n",
       " (979, 10, 0.1163330078125),\n",
       " (980, 10, 0.19921875),\n",
       " (981, 10, 0.1187744140625),\n",
       " (982, 10, 0.11865234375),\n",
       " (983, 10, 0.51220703125),\n",
       " (984, 10, 0.1387939453125),\n",
       " (985, 10, 0.4339599609375),\n",
       " (986, 10, 0.079833984375),\n",
       " (987, 10, 0.065185546875),\n",
       " (988, 10, 0.094970703125),\n",
       " (989, 10, 0.11181640625),\n",
       " (990, 10, 0.2547607421875),\n",
       " (991, 10, 0.1424560546875),\n",
       " (992, 10, 0.316162109375),\n",
       " (993, 9, 0.2171630859375),\n",
       " (994, 10, 0.166748046875),\n",
       " (995, 10, 0.5654296875),\n",
       " (996, 10, 0.189697265625),\n",
       " (997, 10, 0.280517578125),\n",
       " (998, 10, 0.0931396484375),\n",
       " (999, 10, 0.2236328125),\n",
       " ...]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(indexes, Y_test, readouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:12.696490Z",
     "start_time": "2020-10-16T02:34:12.682496Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(183.97222222222223, 0.5, 'Training Readout')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib qt\n",
    "plt.scatter(Y_train, m[-1])\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Training Readout\")\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:13.403732Z",
     "start_time": "2020-10-16T02:34:13.386767Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e08031e808>]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib qt\n",
    "plt.scatter(Y_test, readouts)\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Prediction Readout\")\n",
    "plt.plot([i for i in range(number_negative_class, number_positive_class + 1)], [test_threshold for _ in range(number_negative_class, number_positive_class + 1)])\n",
    "plt.plot([i for i in range(min(number_negative_class, number_positive_class), max(number_negative_class, number_positive_class) + 1)], [test_threshold for _ in range(abs(number_negative_class - number_positive_class) + 1)])\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:14.264290Z",
     "start_time": "2020-10-16T02:34:14.251309Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e08031ec88>]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_auxiliar = classification / np.max(classification)\n",
    "palette = np.array(sns.color_palette(\"hls\", 2))  #Choosing color palette \n",
    "plt.scatter(Y_test, readouts, lw=0, s=40, c=palette[classification_auxiliar.astype(np.int)])\n",
    "plt.plot([i for i in range(number_negative_class, number_positive_class + 1)], [test_threshold for _ in range(number_negative_class, number_positive_class + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:15.072483Z",
     "start_time": "2020-10-16T02:34:15.067520Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ..., 10,  9, 10])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:15.824781Z",
     "start_time": "2020-10-16T02:34:15.818792Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e086f7d808>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(np.array(X_test[2]).reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:16.432225Z",
     "start_time": "2020-10-16T02:34:16.427228Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_test[2]).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:17.239127Z",
     "start_time": "2020-10-16T02:34:17.187224Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e0802b15c8>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.distplot(readouts, bins = 100, kde = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:17.801937Z",
     "start_time": "2020-10-16T02:34:17.786985Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e086f7d108>]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette = np.array(sns.color_palette(\"hls\", 2))  #Choosing color palette \n",
    "plt.scatter(Y_train, m[-1], lw=0, s=40, c=palette[m[-1].astype(np.int)])\n",
    "plt.plot([i for i in range(number_negative_class, number_positive_class + 1)], [test_threshold for _ in range(number_negative_class, number_positive_class + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:18.474704Z",
     "start_time": "2020-10-16T02:34:18.452763Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e0802b15c8>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reads_negative_class = readouts[Y_test == number_negative_class]\n",
    "reads_positive_class = readouts[Y_test == number_positive_class]\n",
    "diff = abs(len(reads_negative_class) - len(reads_positive_class))\n",
    "reads_negative_class = np.pad(reads_negative_class, (0, diff), constant_values=(0, None))\n",
    "d = {str(number_negative_class): reads_negative_class, str(number_positive_class): reads_positive_class}\n",
    "df = pd.DataFrame(data = d)\n",
    "sns.stripplot(data = df, jitter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:34:19.455232Z",
     "start_time": "2020-10-16T02:34:19.451239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = 'weights_OvA_FullDataSet.txt'\n",
    "mode = 'a+'\n",
    "save_weight(filename = filename, mode = mode, weight = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multi label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:24.880018Z",
     "start_time": "2020-10-16T02:51:24.875030Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weights_vector = retrieve_weights_from_file_total(filename = 'weights_OvA_FullDataSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:25.453343Z",
     "start_time": "2020-10-16T02:51:25.258831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_weights_matrix(weights_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:27.881216Z",
     "start_time": "2020-10-16T02:51:27.876212Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
      "  0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0\n",
      "  0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      "  0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(weights_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:28.792261Z",
     "start_time": "2020-10-16T02:51:28.579097Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count for digits: Counter({3: 183, 1: 182, 5: 182, 4: 181, 6: 181, 9: 180, 7: 179, 0: 178, 2: 177, 8: 174})\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "data = np.loadtxt(\"C:/Users/jeff_/OneDrive - Instituto Politecnico Nacional/Datasets/Digits/optdigits.tra\", delimiter = ',')\n",
    "\n",
    "images = digits.images\n",
    "targets = digits.target\n",
    "images_tr = data[:,:-1]\n",
    "labels_tr = data[:,-1]\n",
    "\n",
    "targets_count = Counter(targets)\n",
    "print(f'Total count for digits: {targets_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:30.944217Z",
     "start_time": "2020-10-16T02:51:30.939230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NO SPLITTING FOR RESUSTITUTION ERROR MEASURE\n",
    "X_train = copy(images_tr)\n",
    "X_test = copy(images)\n",
    "Y_train = copy(labels_tr)\n",
    "Y_test = copy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:24:01.975455Z",
     "start_time": "2020-10-16T03:24:01.809749Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(X_test, Y_test))\n",
    "for index, (image, label) in enumerate(images_and_labels[:20]):\n",
    "    plt.subplot(2, 10, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Test: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:35.438155Z",
     "start_time": "2020-10-16T02:51:35.434220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reshaping digits\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:36.473974Z",
     "start_time": "2020-10-16T02:51:36.250573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing digits by mapping in interval\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = np.array(list(map(lambda x : 0 if 0 <= x < 10 else 1, X_test[i])))\n",
    "    \n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = np.array(list(map(lambda x : 0 if 0 <= x < 10 else 1, X_train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:37.608351Z",
     "start_time": "2020-10-16T02:51:37.387745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(X_test, Y_test))\n",
    "for index, (image, label) in enumerate(images_and_labels[:20]):\n",
    "    plt.subplot(2, 10, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('T: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:06:41.684041Z",
     "start_time": "2020-10-16T02:52:51.977113Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8409a6a5b24ca6939219f51dbd075e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd754c589dbd4261bbc8f56da6ab0ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c07450cecd84330bfb2b8b02b13e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e635a803de412585e33f8256cfd338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a6067a9f2045d9bceb7f9f99acd998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2659fb93a447bcbcf088bfe5d42169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a91eb26690c4f1193edf54708b7000f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e21fe097cd14d578f85435169b1e1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaad15b5e8354e5dbdcb1a1a4e109160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67636b0840142d3b2563d4a1c17a2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=1797.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = -1\n",
    "test_threshold = 0.35\n",
    "Q = 6\n",
    "classification_patterns = X_test[:]\n",
    "classification_labels = Y_test[:]\n",
    "shots = 1024 * 8\n",
    "bias = 0.0\n",
    "\n",
    "holder_for_classes, holder_for_readouts = multi_class_prediction_OVA(qubits = Q, classification_patterns = classification_patterns, shots = shots, test_threshold = test_threshold, weights_matrix = weights_vector, bias = bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:06:41.690043Z",
     "start_time": "2020-10-16T03:06:41.686036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To print only two decimal places\n",
    "np.set_printoptions(precision = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:07:34.263691Z",
     "start_time": "2020-10-16T03:07:34.257708Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ...,  7,  8,  9],\n",
       "       [ 0,  1,  2, ...,  7,  8,  9],\n",
       "       [ 0,  1,  2, ...,  7,  8, 10],\n",
       "       ...,\n",
       "       [ 0,  1,  2, ..., 10,  8,  9],\n",
       "       [ 0,  1,  2, ...,  7,  8,  9],\n",
       "       [ 0,  1,  2, ...,  7,  8,  9]], dtype=int64)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_for_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:07:53.981220Z",
     "start_time": "2020-10-16T03:07:53.977209Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mx, my = np.where(holder_for_classes == 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:22:29.604238Z",
     "start_time": "2020-10-16T03:22:29.600285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, j in zip(mx, my):\n",
    "    holder_for_readouts[i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:12:54.512247Z",
     "start_time": "2020-10-16T03:12:54.506230Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17  0.2   0.32 ...  0.27  0.22  0.23]\n",
      " [ 0.19  0.23  0.16 ...  0.32  0.19  0.19]\n",
      " [ 0.21  0.25  0.25 ...  0.16  0.21 10.  ]\n",
      " ...\n",
      " [ 0.17  0.14  0.14 ... 10.    0.16  0.16]\n",
      " [ 0.19  0.29  0.22 ...  0.25  0.24  0.19]\n",
      " [ 0.2   0.17  0.11 ...  0.32  0.19  0.19]]\n"
     ]
    }
   ],
   "source": [
    "print(holder_for_readouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:13:01.413479Z",
     "start_time": "2020-10-16T03:13:01.409489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classified_as = np.argmin(holder_for_readouts, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:08:50.762247Z",
     "start_time": "2020-10-16T03:08:23.803316Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 64 into shape (16,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-413-f4f90b4086be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#c = ax.pcolor(thetas[i + j][1:].reshape(28, 28), cmap = 'gray')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_patterns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gray_r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'equal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 64 into shape (16,16)"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, int(np.ceil(len(classification_patterns) / 3)), figsize=(15,9))\n",
    "count = 0\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(int(np.ceil(len(classification_patterns) / 3))):\n",
    "        ax = axs[i][j]\n",
    "        \n",
    "        #c = ax.pcolor(thetas[i + j][1:].reshape(28, 28), cmap = 'gray')\n",
    "        try:\n",
    "            c = ax.imshow(np.array(classification_patterns[count]).reshape(8, 8), cmap = 'gray_r', interpolation='nearest')\n",
    "            ax.axis('off')\n",
    "            ax.axis('equal')\n",
    "            ax.set_title(f'Clas. as {classified_as[count]} is {classification_labels[count]}').set_position([0.5, 1.1])\n",
    "            count += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.colorbar(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:13:03.485465Z",
     "start_time": "2020-10-16T03:13:03.481508Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.15080690038953812\n"
     ]
    }
   ],
   "source": [
    "accuracy = len(np.where(classification_labels == classified_as)[0]) / len(classification_labels)\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:20:45.662069Z",
     "start_time": "2020-10-16T03:20:45.657083Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holder_for_readouts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:24:39.107660Z",
     "start_time": "2020-10-16T03:24:39.000708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,9))\n",
    "\n",
    "c = ax.imshow(holder_for_readouts[:20 , :], cmap = 'hot', interpolation='nearest')\n",
    "ax.axis('on')\n",
    "#ax.axis('equal')\n",
    "ax.set_title(f'Heatmap for Readouts').set_position([0.5, 1.1])\n",
    "        \n",
    "fig.tight_layout()\n",
    "norm = mpl.colors.Normalize(vmin=np.nan_to_num(holder_for_readouts.astype(float)).min(), vmax=np.nan_to_num(holder_for_readouts.astype(float)).max())\n",
    "plt.colorbar(c, norm = norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:35.868010Z",
     "start_time": "2020-10-16T03:25:35.858045Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   5,   0,   0,  10,   5, 152,   2,   1,   0],\n",
       "       [ 13,   3,   7,   2,   5,   0, 102,  40,  10,   0],\n",
       "       [  0,   0,   5,  28,   9,   5,  70,  36,  11,  13],\n",
       "       [  2,   1,   4,   0,   7,   9,  72,  88,   0,   0],\n",
       "       [ 11,  10,  75,   3,  10,   0,  63,   0,   1,   8],\n",
       "       [  0,   1,   0,  40,   2,   0, 129,   3,   4,   3],\n",
       "       [  1,   1,  50,   0,   0,   0, 129,   0,   0,   0],\n",
       "       [ 15,   8,  12,  19,   2,   1,  12, 106,   2,   2],\n",
       "       [  6,   2,  13,   7,  23,   2,  94,   4,  14,   9],\n",
       "       [  0,   0,   2,   3,  23,   1,  65,  82,   3,   1]], dtype=int64)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(classification_labels, classified_as)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:42.929882Z",
     "start_time": "2020-10-16T03:25:42.770078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(conf, target_names = np.unique(classification_labels), labels = True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:47.393174Z",
     "start_time": "2020-10-16T03:25:47.387189Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15080690038953812"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(classification_labels, classified_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:48.378585Z",
     "start_time": "2020-10-16T03:25:48.367650Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   5,   0,   0,  10,   5, 152,   2,   1,   0],\n",
       "       [ 13,   3,   7,   2,   5,   0, 102,  40,  10,   0],\n",
       "       [  0,   0,   5,  28,   9,   5,  70,  36,  11,  13],\n",
       "       [  2,   1,   4,   0,   7,   9,  72,  88,   0,   0],\n",
       "       [ 11,  10,  75,   3,  10,   0,  63,   0,   1,   8],\n",
       "       [  0,   1,   0,  40,   2,   0, 129,   3,   4,   3],\n",
       "       [  1,   1,  50,   0,   0,   0, 129,   0,   0,   0],\n",
       "       [ 15,   8,  12,  19,   2,   1,  12, 106,   2,   2],\n",
       "       [  6,   2,  13,   7,  23,   2,  94,   4,  14,   9],\n",
       "       [  0,   0,   2,   3,  23,   1,  65,  82,   3,   1]], dtype=int64)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(classification_labels, classified_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:49.266512Z",
     "start_time": "2020-10-16T03:25:49.259529Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06, 0.1 , 0.03, 0.  , 0.11, 0.  , 0.15, 0.29, 0.3 , 0.03])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(classification_labels, classified_as, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:25:54.791549Z",
     "start_time": "2020-10-16T03:25:54.783598Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.02, 0.03, 0.  , 0.06, 0.  , 0.71, 0.59, 0.08, 0.01])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(classification_labels, classified_as, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:26:06.083275Z",
     "start_time": "2020-10-16T03:26:06.075263Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03, 0.03, 0.03, 0.  , 0.07, 0.  , 0.24, 0.39, 0.13, 0.01])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(classification_labels, classified_as, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:26:06.910468Z",
     "start_time": "2020-10-16T03:26:06.904451Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10662744206114369"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(classification_labels, classified_as, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:26:08.590685Z",
     "start_time": "2020-10-16T03:26:08.583736Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15077359343635988"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(classification_labels, classified_as, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:26:10.631282Z",
     "start_time": "2020-10-16T03:26:10.624310Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0927356438903475"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(classification_labels, classified_as, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1166px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
